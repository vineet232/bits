{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d52fadb",
   "metadata": {},
   "source": [
    "### Student information:\n",
    "- Name: Vineet Kumar\n",
    "- Roll No.: 2024AC05100\n",
    "- Assignment-1: Video Classification\n",
    "\n",
    "### Objective 1: (Classical Models)\n",
    "Perform comparative analysis of classical machine learning models for video action classification. \n",
    "\n",
    "The goal is to evaluate and contrast different approaches in terms of predictive performance, computational efficiency, and interpretability.\n",
    "\n",
    "Classical Models compared:\n",
    "- Support Vector Machine (SVM)\n",
    "- Random Forest\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Logistic Regression\n",
    "- Gradient Boosting.\n",
    "\n",
    "### Objective 2: (Deep Learning Models)\n",
    "Perform comparative analysis of deep learning models for video action classification. \n",
    "\n",
    "The goal is to evaluate and contrast different approaches in terms of predictive performance, computational efficiency, and interpretability.\n",
    "\n",
    "Deep Learning Models compared:\n",
    "- 2D-CNN - with temporal pooling (ResNet18 pretrained on ImageNet)\n",
    "- 3D-CNN - pre-trained 3D ResNet-18 (R3D-18), which is an I3D-style 3D CNN architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af616e66",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae1f1b",
   "metadata": {},
   "source": [
    "> Installing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg]);\n",
    "\n",
    "packages = [\"pandas\", \"umap-learn\", \"numpy\"];\n",
    "\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split(\"-\")[0]);\n",
    "    except ImportError:\n",
    "        print(\"Installing package:\", p);\n",
    "        install(p);\n",
    "\n",
    "%pip uninstall -y numpy\n",
    "%pip install numpy==2.3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd4c96",
   "metadata": {},
   "source": [
    "> importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import os;\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc;\n",
    "from sklearn.preprocessing import label_binarize;\n",
    "from sklearn.metrics import ConfusionMatrixDisplay;\n",
    "\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.base import clone;\n",
    "import joblib;\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import warnings\n",
    "import tracemalloc\n",
    "import json\n",
    "\n",
    "from models import ResNet18Temporal, ResNet3D\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from data_loader import VideoDataset2D\n",
    "from data_loader import VideoDataset3D\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2b9ba",
   "metadata": {},
   "source": [
    "> Additional tuning for better and clean results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f72d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "np.random.seed(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8e6a7",
   "metadata": {},
   "source": [
    "> Creating required directories to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../results/feature_visualizations/tsne_umap/\", exist_ok=True); \n",
    "os.makedirs(\"../results/performance_plots/\", exist_ok=True);\n",
    "os.makedirs(\"../results/performance_plots/classical\", exist_ok=True);\n",
    "os.makedirs(\"../results/feature_visualizations/tsne_umap\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938238d",
   "metadata": {},
   "source": [
    "> Loading saved results from Part-A (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Load saved results from Part-A (classical models)\n",
    "# ===================================================\n",
    "\n",
    "y_test = np.load(\"../results/final_classical_y_test.npy\");\n",
    "\n",
    "svm_test_pred = np.load(\"../results/stats_classical/svm_test_pred.npy\");\n",
    "rf_test_pred  = np.load(\"../results/stats_classical/rf_test_pred.npy\");\n",
    "knn_test_pred = np.load(\"../results/stats_classical/knn_test_pred.npy\");\n",
    "logreg_test_pred  = np.load(\"../results/stats_classical/logreg_test_pred.npy\");\n",
    "gb_test_pred  = np.load(\"../results/stats_classical/gb_test_pred.npy\");\n",
    "\n",
    "svm_train_time = np.load(\"../results/stats_classical/svm_train_time.npy\");\n",
    "rf_train_time  = np.load(\"../results/stats_classical/rf_train_time.npy\");\n",
    "knn_train_time = np.load(\"../results/stats_classical/knn_train_time.npy\");\n",
    "logreg_train_time  = np.load(\"../results/stats_classical/logreg_train_time.npy\");\n",
    "gb_train_time  = np.load(\"../results/stats_classical/gb_train_time.npy\");\n",
    "\n",
    "svm_test_time = np.load(\"../results/stats_classical/svm_test_time.npy\");\n",
    "rf_test_time  = np.load(\"../results/stats_classical/rf_test_time.npy\");\n",
    "knn_test_time = np.load(\"../results/stats_classical/knn_test_time.npy\");\n",
    "logreg_test_time  = np.load(\"../results/stats_classical/logreg_test_time.npy\");\n",
    "gb_test_time  = np.load(\"../results/stats_classical/gb_test_time.npy\");\n",
    "\n",
    "svm_acc = np.load(\"../results/stats_classical/svm_accuracy.npy\");\n",
    "rf_acc  = np.load(\"../results/stats_classical/rf_accuracy.npy\");\n",
    "knn_acc = np.load(\"../results/stats_classical/knn_accuracy.npy\");\n",
    "logreg_acc  = np.load(\"../results/stats_classical/logreg_accuracy.npy\");\n",
    "gb_acc  = np.load(\"../results/stats_classical/gb_accuracy.npy\");\n",
    "\n",
    "svm_f1 = np.load(\"../results/stats_classical/svm_f1.npy\");\n",
    "rf_f1  = np.load(\"../results/stats_classical/rf_f1.npy\");\n",
    "knn_f1 = np.load(\"../results/stats_classical/knn_f1.npy\");\n",
    "logreg_f1  = np.load(\"../results/stats_classical/logreg_f1.npy\");\n",
    "gb_f1  = np.load(\"../results/stats_classical/gb_f1.npy\");\n",
    "\n",
    "best_svm = joblib.load(\"../results/saved_models/classical/svm_trained_model.joblib\");\n",
    "best_rf = joblib.load(\"../results/saved_models/classical/rf_trained_model.joblib\");\n",
    "best_knn = joblib.load(\"../results/saved_models/classical/knn_trained_model.joblib\");\n",
    "logreg = joblib.load(\"../results/saved_models/classical/logreg_trained_model.joblib\");\n",
    "gb = joblib.load(\"../results/saved_models/classical/gb_trained_model.joblib\");\n",
    "\n",
    "X_train = np.load(\"../results/saved_feature_matrices/X_train.npy\");\n",
    "X_val   = np.load(\"../results/saved_feature_matrices/X_val.npy\");\n",
    "X_test  = np.load(\"../results/saved_feature_matrices/X_test.npy\");\n",
    "\n",
    "y_train = np.load(\"../results/saved_feature_matrices/y_train.npy\");\n",
    "y_val   = np.load(\"../results/saved_feature_matrices/y_val.npy\");\n",
    "y_test  = np.load(\"../results/saved_feature_matrices/y_test.npy\");\n",
    "\n",
    "X_test_rf   = np.load(\"../results/stats_classical/X_test_rf.npy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893451d",
   "metadata": {},
   "source": [
    "### Classical models: Evaluation Metrices Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae2c6c",
   "metadata": {},
   "source": [
    "1. Classical models: Highlighting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "acc_list = [];\n",
    "prec_list = [];\n",
    "rec_list = [];\n",
    "f1_list = [];\n",
    "\n",
    "for p in preds:\n",
    "    acc_list.append(accuracy_score(y_test, p));\n",
    "    prec_list.append(precision_score(y_test, p, average=\"macro\"));\n",
    "    rec_list.append(recall_score(y_test, p, average=\"macro\"));\n",
    "    f1_list.append(f1_score(y_test, p, average=\"macro\"));\n",
    "\n",
    "# Create comparison dataframe\n",
    "perf_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Accuracy\": acc_list,\n",
    "    \"Precision\": prec_list,\n",
    "    \"Recall\": rec_list,\n",
    "    \"F1-score\": f1_list\n",
    "});\n",
    "\n",
    "\n",
    "perf_df\n",
    "\n",
    "# Printing the table and Highlighting the best model\n",
    "def highlight_best(s):\n",
    "    is_best = s == s.max();\n",
    "    return [\"background-color: red\" if v else \"\" for v in is_best];\n",
    "\n",
    "perf_df.style.apply(highlight_best, subset=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e404aa0",
   "metadata": {},
   "source": [
    "2. Classical models: Accuracy Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(perf_df[\"Model\"], perf_df[\"Accuracy\"]);\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Accuracy\");\n",
    "plt.title(\"Accuracy Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/accuracy_comparison.png\", dpi=300);\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c109aae",
   "metadata": {},
   "source": [
    "3. Classical models: F1-Score Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(perf_df[\"Model\"], perf_df[\"F1-score\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"F1-score\");\n",
    "plt.title(\"F1-score Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/f1_score_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad90aa1",
   "metadata": {},
   "source": [
    "4. Classical models: Precision and Recall grouped plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(perf_df));\n",
    "width = 0.35;\n",
    "\n",
    "plt.figure(figsize=(9,5));\n",
    "plt.bar(x - width/2, perf_df[\"Precision\"], width, label=\"Precision\");\n",
    "plt.bar(x + width/2, perf_df[\"Recall\"], width, label=\"Recall\");\n",
    "\n",
    "plt.xticks(x, perf_df[\"Model\"], rotation=30);\n",
    "plt.ylabel(\"Score\");\n",
    "plt.title(\"Precision and Recall Comparison\");\n",
    "plt.legend();\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/precision_recall_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378accb",
   "metadata": {},
   "source": [
    "5. Classical models: ROC multiclass comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels (0,1,2)\n",
    "classes = np.unique(y_test);\n",
    "n_classes = len(classes);\n",
    "\n",
    "# Binarize true labels\n",
    "y_test_bin = label_binarize(y_test, classes=classes);\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "plt.figure(figsize=(9,7));\n",
    "\n",
    "for model_name, y_pred in zip(models, preds):\n",
    "    \n",
    "    # Binarize predictions\n",
    "    y_pred_bin = label_binarize(y_pred, classes=classes);\n",
    "    \n",
    "    fpr = dict();\n",
    "    tpr = dict();\n",
    "    roc_auc = dict();\n",
    "    \n",
    "    # ROC per class\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i]);\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i]);\n",
    "    \n",
    "    # Macro-average ROC\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]));\n",
    "    mean_tpr = np.zeros_like(all_fpr);\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i]);\n",
    "\n",
    "    mean_tpr /= n_classes;\n",
    "    macro_auc = auc(all_fpr, mean_tpr);\n",
    "\n",
    "    plt.plot(all_fpr, mean_tpr, lw=2,\n",
    "             label=f\"{model_name} (AUC = {macro_auc:.3f})\");\n",
    "\n",
    "# Random guess line\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=1);\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\");\n",
    "plt.ylabel(\"True Positive Rate\");\n",
    "plt.title(\"Multi-class ROC Curve Comparison (Macro-average)\");\n",
    "plt.legend(loc=\"lower right\");\n",
    "plt.grid(True);\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/roc_auc_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca8a2f",
   "metadata": {},
   "source": [
    "6. Classical models: Confusion matrix comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9));\n",
    "axes = axes.ravel();\n",
    "\n",
    "for i, (name, y_pred) in enumerate(zip(models, preds)):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        ax=axes[i],\n",
    "        cmap=\"Blues\",\n",
    "        colorbar=False\n",
    "    );\n",
    "    axes[i].set_title(name);\n",
    "\n",
    "# remove empty subplot (6th one)\n",
    "axes[-1].axis(\"off\");\n",
    "\n",
    "fig.suptitle(\"Confusion Matrix Comparison – Classical Models\", fontsize=16);\n",
    "plt.tight_layout();\n",
    "plt.subplots_adjust(top=0.92);\n",
    "\n",
    "plt.savefig(\"../results/performance_plots/classical/confusion_matrix_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37b04a",
   "metadata": {},
   "source": [
    "### Classical models: Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f20167",
   "metadata": {},
   "source": [
    "1. Classical models: Training time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Computational Efficiency: Training Time Comparison\n",
    "# ===================================================\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "train_times = [\n",
    "    svm_train_time, \n",
    "    rf_train_time, \n",
    "    knn_train_time, \n",
    "    logreg_train_time, \n",
    "    gb_train_time\n",
    "];\n",
    "\n",
    "# Create dataframe for display\n",
    "train_time_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Training Time (seconds)\": train_times\n",
    "});\n",
    "\n",
    "train_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439903ad",
   "metadata": {},
   "source": [
    "- Plot: Training time comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(models, train_times);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Training Time (seconds)\");\n",
    "plt.title(\"Training Time Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/training_time_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7259810",
   "metadata": {},
   "source": [
    "2. Classical models: Inference time per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87caf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Inference Time per Video (seconds)\n",
    "# ============================================\n",
    "\n",
    "num_test_videos = len(y_test)\n",
    "\n",
    "inf_times = [\n",
    "    svm_test_time / num_test_videos,\n",
    "    rf_test_time / num_test_videos,\n",
    "    knn_test_time / num_test_videos,\n",
    "    logreg_test_time / num_test_videos,\n",
    "    gb_test_time / num_test_videos\n",
    "]\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "\n",
    "inf_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Inference Time per Video (s)\": inf_times\n",
    "})\n",
    "\n",
    "inf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8eee2d",
   "metadata": {},
   "source": [
    "- Plot: Inference time per video (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Plot: Inference time per video\n",
    "# ============================================\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(inf_df[\"Model\"], inf_df[\"Inference Time per Video (s)\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Seconds per video\");\n",
    "plt.title(\"Inference Time per Video – Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/inference_time_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03a169",
   "metadata": {},
   "source": [
    "3. Classical models: Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Model Size (Disk footprint in MB)\n",
    "# ============================================\n",
    "\n",
    "model_files = {\n",
    "    \"SVM\": \"../results/saved_models/classical/svm_trained_model.joblib\",\n",
    "    \"Random Forest\": \"../results/saved_models/classical/rf_trained_model.joblib\",\n",
    "    \"k-NN\": \"../results/saved_models/classical/knn_trained_model.joblib\",\n",
    "    \"Logistic Regression\": \"../results/saved_models/classical/logreg_trained_model.joblib\",\n",
    "    \"Gradient Boosting\": \"../results/saved_models/classical/gb_trained_model.joblib\"\n",
    "};\n",
    "\n",
    "sizes = [];\n",
    "\n",
    "for model, path in model_files.items():\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024);\n",
    "        sizes.append([model, size_mb]);\n",
    "    else:\n",
    "        sizes.append([model, np.nan]);\n",
    "\n",
    "size_df = pd.DataFrame(sizes, columns=[\"Model\", \"Model Size (MB)\"]);\n",
    "size_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd604c",
   "metadata": {},
   "source": [
    "- Plot: Model size comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Plot: Model size comparison\n",
    "# ============================================\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(size_df[\"Model\"], size_df[\"Model Size (MB)\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Model size (MB)\");\n",
    "plt.title(\"Model Size Comparison – Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/classical/model_size_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db013820",
   "metadata": {},
   "source": [
    "4. Classical models: Data Efficiency Analysis\n",
    "\n",
    "- This step will take around 15 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data splits\n",
    "\n",
    "#fractions = [0.1, 0.3, 0.5, 0.7, 1.0];\n",
    "fractions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "\n",
    "# Store original full training data\n",
    "\n",
    "X_full = np.vstack([X_train, X_val]);\n",
    "y_full = np.hstack([y_train, y_val]);\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVM\": best_svm,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"k-NN\": best_knn,\n",
    "    \"Logistic Regression\": logreg,\n",
    "    \"Gradient Boosting\": gb\n",
    "};\n",
    "\n",
    "# Computing learning curves:\n",
    "learning_results = {name: [] for name in models}\n",
    "\n",
    "for i, frac in enumerate(fractions):\n",
    "\n",
    "    print(f\"\\n========== Training with {int(frac*100)}% data ==========\")\n",
    "\n",
    "    X_sub, _, y_sub, _ = train_test_split(\n",
    "        X_full, y_full,\n",
    "        train_size=frac,\n",
    "        stratify=y_full,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for name, model in tqdm(models.items(),\n",
    "                             desc=f\"Models @ {int(frac*100)}%\",\n",
    "                             position=0,\n",
    "                             leave=True):\n",
    "\n",
    "        temp_model = clone(model)\n",
    "        temp_model.fit(X_sub, y_sub)\n",
    "\n",
    "        preds = temp_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "\n",
    "        learning_results[name].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efc652",
   "metadata": {},
   "source": [
    "- Plot: Learning curves comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9627a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the learning curves\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for name, accs in learning_results.items():\n",
    "    plt.plot([int(f*100) for f in fractions], accs, marker=\"o\", label=name)\n",
    "\n",
    "plt.xlabel(\"Training data size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Learning Curves – Data Efficiency Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/performance_plots/classical/learning_curves.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9e39f",
   "metadata": {},
   "source": [
    "5. Classical models: Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff800452",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_results = []\n",
    "\n",
    "models = {\n",
    "    \"SVM\": best_svm,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"k-NN\": best_knn,\n",
    "    \"Logistic Regression\": logreg,\n",
    "    \"Gradient Boosting\": gb\n",
    "};\n",
    "\n",
    "for name, model in models.items():\n",
    "    tracemalloc.start()\n",
    "\n",
    "    if name == \"Random Forest\":\n",
    "        _ = model.predict(X_test_rf)\n",
    "    else:\n",
    "        _ = model.predict(X_test)\n",
    "\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    memory_results.append([name, peak/(1024*1024)]) # MB\n",
    "\n",
    "memory_df = pd.DataFrame(memory_results, columns=[\"Model\", \"Peak Memory Usage (MB)\"])\n",
    "memory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ac05f",
   "metadata": {},
   "source": [
    "- Plot: Memory requirements (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(memory_df[\"Model\"], memory_df[\"Peak Memory Usage (MB)\"])\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Peak RAM Usage (MB)\")\n",
    "plt.title(\"Memory Requirement Comparison (Inference)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/performance_plots/classical/memory_usage_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353c5e0",
   "metadata": {},
   "source": [
    "6. Classical models: t-SNE Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22209a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- Normalize features (important for t-SNE) --------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# -------- Run t-SNE --------\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    learning_rate=200,\n",
    "    max_iter=1500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# -------- Plot --------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for label in np.unique(y_test):\n",
    "    idx = y_test == label\n",
    "    plt.scatter(X_tsne[idx,0], X_tsne[idx,1], s=30, label=f\"Class {label}\")\n",
    "\n",
    "plt.title(\"t-SNE visualization of handcrafted video features\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../results/feature_visualizations/tsne_umap/tsne_classical.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f63b1f",
   "metadata": {},
   "source": [
    "7. Classical models: UMAP Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c879f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- Run UMAP --------\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_umap = umap_model.fit_transform(X_scaled)\n",
    "\n",
    "# -------- Plot --------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for label in np.unique(y_test):\n",
    "    idx = y_test == label\n",
    "    plt.scatter(X_umap[idx,0], X_umap[idx,1], s=30, label=f\"Class {label}\")\n",
    "\n",
    "plt.title(\"UMAP visualization of handcrafted video features\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../results/feature_visualizations/tsne_umap/umap_classical.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52158b",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f8f18",
   "metadata": {},
   "source": [
    "### Deep Learning models: Evaluation Metrices Comparison\n",
    "\n",
    "This section compares the performance of deep learning-based video classification approaches:\n",
    "1. 2D CNN with Temporal Pooling (ResNet-18)\n",
    "2. 3D CNN (I3D-style ResNet-3D)\n",
    "\n",
    "The models are compared based on accuracy, precision, recall, F1-score, inference time, and model size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01098e",
   "metadata": {},
   "source": [
    "> Loading json files and saved results from Part-B (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e917690",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/stats_deep_learning/stats_2d.json\") as f:\n",
    "    stats_2d = json.load(f)\n",
    "\n",
    "with open(\"../results/stats_deep_learning/stats_3d.json\") as f:\n",
    "    stats_3d = json.load(f)\n",
    "\n",
    "deep_learning_results = {\n",
    "    \"2D CNN (ResNet18)\": stats_2d,\n",
    "    \"3D CNN (ResNet3D)\": stats_3d\n",
    "}\n",
    "\n",
    "all_preds_2d  = np.load(\"../results/stats_deep_learning/preds_2d.npy\")\n",
    "all_labels_2d = np.load(\"../results/stats_deep_learning/labels_2d.npy\")\n",
    "\n",
    "all_preds_3d  = np.load(\"../results/stats_deep_learning/preds_3d.npy\")\n",
    "all_labels_3d = np.load(\"../results/stats_deep_learning/labels_3d.npy\")\n",
    "\n",
    "\n",
    "\n",
    "df_dl = pd.DataFrame(deep_learning_results).T\n",
    "df_dl_pretty = df_dl.rename(columns={\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "    \"precision\": \"Precision\",\n",
    "    \"recall\": \"Recall\",\n",
    "    \"f1\": \"F1-Score\",\n",
    "    \"inference_time\": \"Inference time (s/video)\",\n",
    "    \"params\": \"Parameters (Millions)\",\n",
    "    \"model_size_mb\": \"Model size (MB)\"\n",
    "})\n",
    "df_dl_pretty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c27de",
   "metadata": {},
   "source": [
    "> Creating directory to save comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = \"../results/performance_plots/deep_learning\";\n",
    "os.makedirs(PLOT_DIR, exist_ok=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470895c",
   "metadata": {},
   "source": [
    "1. Deep Learning models: Highlighting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae82a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting the best deep learning model based on Accuracy:\n",
    "\n",
    "best_model = df_dl_pretty[\"Accuracy\"].idxmax()\n",
    "\n",
    "def highlight_best(row):\n",
    "    if row.name == best_model:\n",
    "        return [\"background-color: red\"] * len(row)\n",
    "    return [\"\"] * len(row)\n",
    "\n",
    "df_dl_pretty.style.apply(highlight_best, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cb699",
   "metadata": {},
   "source": [
    "2. Deep Learning Models: Accuracy Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_dl_pretty.index, df_dl_pretty[\"Accuracy\"])\n",
    "plt.title(\"Accuracy Comparison (2D CNN vs 3D CNN)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_models_accuracy_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d73dfc",
   "metadata": {},
   "source": [
    "3. Deep Learning Models: F1-score Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370def02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_dl_pretty.index, df_dl_pretty[\"F1-Score\"])\n",
    "plt.title(\"F1-Score Comparison (2D CNN vs 3D CNN)\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_models_f1_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f25e4",
   "metadata": {},
   "source": [
    "4. Deep Learning Models: Precision and Recall grouped Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c579714",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = df_dl_pretty.index.tolist()\n",
    "\n",
    "precision = df_dl_pretty[\"Precision\"].values\n",
    "recall = df_dl_pretty[\"Recall\"].values\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x - width/2, precision, width, label=\"Precision\")\n",
    "plt.bar(x + width/2, recall, width, label=\"Recall\")\n",
    "\n",
    "plt.xticks(x, models)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Precision & Recall Comparison (Deep Learning Models)\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(PLOT_DIR, \"deep_learning_precision_recall_comparison.png\"),\n",
    "    dpi=300\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d318b1",
   "metadata": {},
   "source": [
    "5. Deep Learning Models: ROC multiclass comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb95ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Basic setup\n",
    "# ===============================\n",
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "num_classes = len(class_map)\n",
    "classes = np.arange(num_classes)\n",
    "\n",
    "models = {\n",
    "    \"2D CNN (ResNet18)\": (all_labels_2d, all_preds_2d),\n",
    "    \"3D CNN (ResNet3D)\": (all_labels_3d, all_preds_3d),\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# ROC–AUC Plot\n",
    "# ===============================\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for model_name, (y_true, y_pred) in models.items():\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    y_pred_bin = label_binarize(y_pred, classes=classes)\n",
    "\n",
    "    fpr, tpr = {}, {}\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "\n",
    "    # ----- Macro-average ROC -----\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    mean_tpr /= num_classes\n",
    "    macro_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "    plt.plot(\n",
    "        all_fpr, mean_tpr,\n",
    "        lw=2,\n",
    "        label=f\"{model_name} (Macro AUC = {macro_auc:.3f})\"\n",
    "    )\n",
    "\n",
    "# Random baseline\n",
    "plt.plot([0,1], [0,1], \"k--\", lw=1)\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC–AUC Comparison (Deep Learning Models)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(PLOT_DIR, \"deep_learning_roc_auc_comparison.png\"),\n",
    "    dpi=300\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a408ba",
   "metadata": {},
   "source": [
    "6. Deep Learning Models: Confusion matrix comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d542db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "class_names = list(class_map.keys())\n",
    "\n",
    "y_true_2d = np.load(\"../results/stats_deep_learning/labels_2d.npy\")\n",
    "y_pred_2d = np.load(\"../results/stats_deep_learning/preds_2d.npy\")\n",
    "\n",
    "y_true_3d = np.load(\"../results/stats_deep_learning/labels_3d.npy\")\n",
    "y_pred_3d = np.load(\"../results/stats_deep_learning/preds_3d.npy\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true_2d, y_pred_2d,\n",
    "    display_labels=class_names,\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[0],\n",
    "    colorbar=False\n",
    ")\n",
    "axes[0].set_title(\"2D CNN (ResNet18)\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true_3d, y_pred_3d,\n",
    "    display_labels=class_names,\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[1],\n",
    "    colorbar=False\n",
    ")\n",
    "axes[1].set_title(\"3D CNN (ResNet3D)\")\n",
    "\n",
    "fig.suptitle(\"Confusion Matrix Comparison – Deep Learning Models\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(PLOT_DIR, \"deep_learning_confusion_matrix_comparison.png\"),\n",
    "    dpi=300\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fa179",
   "metadata": {},
   "source": [
    "### Deep Learning Models: Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca644ed",
   "metadata": {},
   "source": [
    "1. Deep Learning Models: Training time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e444b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_2d = np.load(\"../results/stats_deep_learning/train_time_2d.npy\")\n",
    "train_time_3d = np.load(\"../results/stats_deep_learning/train_time_3d.npy\")\n",
    "\n",
    "models = [\"2D CNN (ResNet18)\", \"3D CNN (ResNet3D)\"]\n",
    "train_times = [train_time_2d, train_time_3d]\n",
    "\n",
    "# ===============================\n",
    "# Table\n",
    "# ===============================\n",
    "train_time_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Training Time (seconds)\": train_times\n",
    "})\n",
    "\n",
    "train_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90473528",
   "metadata": {},
   "source": [
    "- Plot: Training time comparison (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(models, train_times)\n",
    "plt.ylabel(\"Training Time (seconds)\")\n",
    "plt.title(\"Training Time Comparison – Deep Learning Models\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(PLOT_DIR, \"deep_learning_training_time_comparison.png\"),\n",
    "    dpi=300\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e289b",
   "metadata": {},
   "source": [
    "2. Deep Learning Models: Inference time per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_time_2d = np.load(\"../results/stats_deep_learning/inf_time_2d.npy\")\n",
    "inf_time_3d = np.load(\"../results/stats_deep_learning/inf_time_3d.npy\")\n",
    "\n",
    "df_inf = pd.DataFrame({\n",
    "    \"Model\": [\"2D CNN (ResNet18)\", \"3D CNN (ResNet3D)\"],\n",
    "    \"Inference Time per Video (s)\": [inf_time_2d, inf_time_3d]\n",
    "})\n",
    "\n",
    "df_inf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028dc09",
   "metadata": {},
   "source": [
    "- Plot: Inference time per video (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5faf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_dl_pretty.index, df_dl_pretty[\"Inference time (s/video)\"])\n",
    "plt.title(\"Inference Time per Video (2D CNN vs 3D CNN)\")\n",
    "plt.ylabel(\"Seconds per video\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_models_inference_time_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc84552",
   "metadata": {},
   "source": [
    "3. Deep Learning Models: Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_2d = np.load(\"../results/stats_deep_learning/model_size_2d.npy\")\n",
    "size_3d = np.load(\"../results/stats_deep_learning/model_size_3d.npy\")\n",
    "\n",
    "df_size = pd.DataFrame({\n",
    "    \"Model\": [\"2D CNN (ResNet18)\", \"3D CNN (ResNet3D)\"],\n",
    "    \"Model Size (MB)\": [size_2d, size_3d]\n",
    "})\n",
    "\n",
    "df_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435dee3",
   "metadata": {},
   "source": [
    "- Plot: Model Size Comparison (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_dl_pretty.index, df_dl_pretty[\"Model size (MB)\"])\n",
    "plt.title(\"Model Size Comparison (2D CNN vs 3D CNN)\")\n",
    "plt.ylabel(\"Model size (MB)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_models_size_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46da25",
   "metadata": {},
   "source": [
    "4. Deep Learning Models: Data Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20463fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Transforms ----------------\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ---------------- Setup ----------------\n",
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "num_classes = len(class_map)\n",
    "dataset_root = \"../dataset_info/dataset\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------- Datasets ----------------\n",
    "train_ds_2d = VideoDataset2D(\n",
    "    \"../dataset_info/dataset/splits/train.csv\",\n",
    "    dataset_root, class_map,\n",
    "    num_frames=16,\n",
    "    transform=train_tfms,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "train_ds_3d = VideoDataset3D(\n",
    "    \"../dataset_info/dataset/splits/train.csv\",\n",
    "    dataset_root, class_map,\n",
    "    num_frames=16,\n",
    "    transform=train_tfms,   # applied per-frame internally (ok)\n",
    "    train=True\n",
    ")\n",
    "\n",
    "\n",
    "#............ Models .............\n",
    "model_2d = ResNet18Temporal(num_classes=num_classes, pooling=\"avg\", dropout=0.5).to(device)\n",
    "model_3d = ResNet3D(num_classes=num_classes, dropout=0.5, freeze_backbone=True).to(device)\n",
    "\n",
    "# ---------------- Fractions ----------------\n",
    "fractions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "learning_results_dl = {\n",
    "    \"2D CNN (ResNet18)\": [],\n",
    "    \"3D CNN (ResNet3D)\": []\n",
    "}\n",
    "\n",
    "# ---------------- Eval helper ----------------\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = torch.argmax(model(x), dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# ---------------- Data Efficiency Loop ----------------\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(train_ds_2d))   # same CSV → safe\n",
    "\n",
    "for frac in fractions:\n",
    "    print(f\"\\n==== Using {int(frac*100)}% training data ====\")\n",
    "\n",
    "    sub_size = int(len(indices) * frac)\n",
    "    sub_idx = np.random.choice(indices, sub_size, replace=False)\n",
    "\n",
    "    subset_2d = Subset(train_ds_2d, sub_idx)\n",
    "    subset_3d = Subset(train_ds_3d, sub_idx)\n",
    "\n",
    "    loader_2d = DataLoader(\n",
    "        subset_2d,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    loader_3d = DataLoader(\n",
    "        subset_3d,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    acc_2d = evaluate_model(model_2d, loader_2d, device)\n",
    "    acc_3d = evaluate_model(model_3d, loader_3d, device)\n",
    "\n",
    "    learning_results_dl[\"2D CNN (ResNet18)\"].append(acc_2d)\n",
    "    learning_results_dl[\"3D CNN (ResNet3D)\"].append(acc_3d)\n",
    "\n",
    "    print(f\"2D Acc: {acc_2d:.4f} | 3D Acc: {acc_3d:.4f}\")\n",
    "\n",
    "# ---------------- Save once (correct way) ----------------\n",
    "os.makedirs(\"../results/stats_deep_learning\", exist_ok=True)\n",
    "np.save(\n",
    "    \"../results/stats_deep_learning/learning_results_dl.npy\",\n",
    "    learning_results_dl,\n",
    "    allow_pickle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de254378",
   "metadata": {},
   "source": [
    "Plot: Learning curves comparison (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f16cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for model_name, accs in learning_results_dl.items():\n",
    "    plt.plot(\n",
    "        [int(f*100) for f in fractions],\n",
    "        accs,\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "        label=model_name\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Training data size (%)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Learning Curves – Data Efficiency Comparison\");\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_data_efficiency.png\"), dpi=300);\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c86d4f",
   "metadata": {},
   "source": [
    "5. Deep Learning Models: Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce775964",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_2d = torch.randn(1, 16, 3, 224, 224).to(device)\n",
    "dummy_3d = torch.randn(1, 3, 16, 224, 224).to(device)\n",
    "\n",
    "dummy_inputs = {\n",
    "    \"2D CNN (ResNet18)\": dummy_2d,\n",
    "    \"3D CNN (ResNet3D)\": dummy_3d\n",
    "}\n",
    "\n",
    "memory_results_dl = []\n",
    "\n",
    "models = {\n",
    "    \"2D CNN (ResNet18)\": model_2d,\n",
    "    \"3D CNN (ResNet3D)\": model_3d\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    tracemalloc.start()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_inputs[name])\n",
    "\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    memory_results_dl.append([\n",
    "        name,\n",
    "        peak / (1024 * 1024)   # MB\n",
    "    ])\n",
    "\n",
    "memory_df_dl = pd.DataFrame(\n",
    "    memory_results_dl,\n",
    "    columns=[\"Model\", \"Peak Memory Usage (MB)\"]\n",
    ")\n",
    "\n",
    "memory_df_dl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c222ac",
   "metadata": {},
   "source": [
    "- Plot: Memory requirements (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(memory_df_dl[\"Model\"], memory_df_dl[\"Peak Memory Usage (MB)\"])\n",
    "plt.ylabel(\"Peak Memory Usage (MB)\")\n",
    "plt.title(\"Memory Usage Comparison (Deep Learning Models)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"deep_learning_memory_usage_comparison.png\"), dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c3b30",
   "metadata": {},
   "source": [
    "6. Deep Learning Models: t-SNE Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== CONFIG ==================\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "dataset_root = \"../dataset_info/dataset\"\n",
    "\n",
    "# ================== LOAD TEST DATA ==================\n",
    "\n",
    "# ---------- 2D ----------\n",
    "test_ds_2d = VideoDataset2D(\n",
    "    \"../dataset_info/dataset/splits/test.csv\",\n",
    "    dataset_root,\n",
    "    class_map,\n",
    "    num_frames=16,\n",
    "    transform=val_tfms,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "test_loader_2d = DataLoader(\n",
    "    test_ds_2d,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# ---------- 3D ----------\n",
    "test_ds_3d = VideoDataset3D(\n",
    "    \"../dataset_info/dataset/splits/test.csv\",\n",
    "    dataset_root,\n",
    "    class_map,\n",
    "    num_frames=16,\n",
    "    transform=val_tfms,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "test_loader_3d = DataLoader(\n",
    "    test_ds_3d,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# ================== FEATURE EXTRACTION ==================\n",
    "\n",
    "def extract_features_2d(model, loader, device):\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)   # (B,T,C,H,W)\n",
    "\n",
    "            B, T, C, H, W = x.shape\n",
    "            x = x.view(B*T, C, H, W)\n",
    "\n",
    "            f = model.feature_extractor(x)\n",
    "            f = f.squeeze(-1).squeeze(-1)     # (B*T,512)\n",
    "            f = f.view(B, T, -1).mean(dim=1)  # temporal pooling\n",
    "\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    return np.vstack(feats), np.hstack(labels)\n",
    "\n",
    "\n",
    "def extract_features_3d(model, loader, device):\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)   # (B,C,T,H,W)\n",
    "            f = model.backbone(x)   # already pooled (B,512)\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    return np.vstack(feats), np.hstack(labels)\n",
    "\n",
    "\n",
    "# ================== RUN EXTRACTION ==================\n",
    "\n",
    "X_2d, y_2d = extract_features_2d(model_2d, test_loader_2d, device)\n",
    "X_3d, y_3d = extract_features_3d(model_3d, test_loader_3d, device)\n",
    "\n",
    "# ================== t-SNE PLOT ==================\n",
    "\n",
    "def tsne_plot(X, y, title, filename):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=30,\n",
    "        learning_rate=200,\n",
    "        max_iter=1500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for label in np.unique(y):\n",
    "        idx = y == label\n",
    "        plt.scatter(\n",
    "            X_tsne[idx, 0],\n",
    "            X_tsne[idx, 1],\n",
    "            s=30,\n",
    "            label=f\"Class {label}\"\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE Component 1\")\n",
    "    plt.ylabel(\"t-SNE Component 2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(PLOT_DIR, filename)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================== GENERATE PLOTS ==================\n",
    "\n",
    "tsne_plot(\n",
    "    X_2d, y_2d,\n",
    "    \"t-SNE Visualization – 2D CNN Feature Space\",\n",
    "    \"tsne_2d_cnn.png\"\n",
    ")\n",
    "\n",
    "tsne_plot(\n",
    "    X_3d, y_3d,\n",
    "    \"t-SNE Visualization – 3D CNN Feature Space\",\n",
    "    \"tsne_3d_cnn.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c9e67",
   "metadata": {},
   "source": [
    "7. Deep Learning Models: UMAP Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3778865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_plot(X, y, title, save_path):\n",
    "    # Normalize features\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # UMAP\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_umap = umap_model.fit_transform(X_scaled)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for label in np.unique(y):\n",
    "        idx = y == label\n",
    "        plt.scatter(\n",
    "            X_umap[idx, 0],\n",
    "            X_umap[idx, 1],\n",
    "            s=30,\n",
    "            label=f\"Class {label}\"\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"UMAP Component 1\")\n",
    "    plt.ylabel(\"UMAP Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "umap_plot(\n",
    "    X_2d,\n",
    "    y_2d,\n",
    "    title=\"UMAP Visualization – 2D CNN (ResNet18)\",\n",
    "    save_path=os.path.join(PLOT_DIR, \"umap_2dcnn.png\")\n",
    ")\n",
    "\n",
    "umap_plot(\n",
    "    X_3d,\n",
    "    y_3d,\n",
    "    title=\"UMAP Visualization – 3D CNN (ResNet3D)\",\n",
    "    save_path=os.path.join(PLOT_DIR, \"umap_3dcnn.png\")\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
