{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d52fadb",
   "metadata": {},
   "source": [
    "### Student information:\n",
    "- Name: Vineet Kumar\n",
    "- Roll No.: 2024AC05100\n",
    "- Assignment-1: Video Classification\n",
    "\n",
    "### Objective 1: (Classical Models)\n",
    "Perform comparative analysis of classical machine learning models for video action classification. \n",
    "\n",
    "The goal is to evaluate and contrast different approaches in terms of predictive performance, computational efficiency, and interpretability.\n",
    "\n",
    "Classical Models compared:\n",
    "- Support Vector Machine (SVM)\n",
    "- Random Forest\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Logistic Regression\n",
    "- Gradient Boosting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af616e66",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae1f1b",
   "metadata": {},
   "source": [
    "> Installing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg]);\n",
    "\n",
    "packages = [\"pandas\", \"umap-learn\"];\n",
    "\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split(\"-\")[0]);\n",
    "    except ImportError:\n",
    "        print(\"Installing package:\", p);\n",
    "        install(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd4c96",
   "metadata": {},
   "source": [
    "> importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import os;\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc;\n",
    "from sklearn.preprocessing import label_binarize;\n",
    "from sklearn.metrics import ConfusionMatrixDisplay;\n",
    "\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.base import clone;\n",
    "import joblib;\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import warnings\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2b9ba",
   "metadata": {},
   "source": [
    "Additional tuning for better and clean results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f72d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "np.random.seed(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8e6a7",
   "metadata": {},
   "source": [
    "Creating required directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "os.makedirs(\"../results/saved_models\", exist_ok=True);\n",
    "os.makedirs(\"../results/feature_visualizations/tsne_umap/\", exist_ok=True); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938238d",
   "metadata": {},
   "source": [
    "> Load saved results from Part-A (classical models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Load saved results from Part-A (classical models)\n",
    "# ===================================================\n",
    "\n",
    "y_test = np.load(\"../results/y_test.npy\");\n",
    "\n",
    "svm_test_pred = np.load(\"../results/svm_test_pred.npy\");\n",
    "rf_test_pred  = np.load(\"../results/rf_test_pred.npy\");\n",
    "knn_test_pred = np.load(\"../results/knn_test_pred.npy\");\n",
    "logreg_test_pred  = np.load(\"../results/logreg_test_pred.npy\");\n",
    "gb_test_pred  = np.load(\"../results/gb_test_pred.npy\");\n",
    "\n",
    "svm_train_time = np.load(\"../results/svm_train_time.npy\");\n",
    "rf_train_time  = np.load(\"../results/rf_train_time.npy\");\n",
    "knn_train_time = np.load(\"../results/knn_train_time.npy\");\n",
    "logreg_train_time  = np.load(\"../results/logreg_train_time.npy\");\n",
    "gb_train_time  = np.load(\"../results/gb_train_time.npy\");\n",
    "\n",
    "svm_test_time = np.load(\"../results/svm_test_time.npy\");\n",
    "rf_test_time  = np.load(\"../results/rf_test_time.npy\");\n",
    "knn_test_time = np.load(\"../results/knn_test_time.npy\");\n",
    "logreg_test_time  = np.load(\"../results/logreg_test_time.npy\");\n",
    "gb_test_time  = np.load(\"../results/gb_test_time.npy\");\n",
    "\n",
    "svm_acc = np.load(\"../results/svm_accuracy.npy\");\n",
    "rf_acc  = np.load(\"../results/rf_accuracy.npy\");\n",
    "knn_acc = np.load(\"../results/knn_accuracy.npy\");\n",
    "logreg_acc  = np.load(\"../results/logreg_accuracy.npy\");\n",
    "gb_acc  = np.load(\"../results/gb_accuracy.npy\");\n",
    "\n",
    "svm_f1 = np.load(\"../results/svm_f1.npy\");\n",
    "rf_f1  = np.load(\"../results/rf_f1.npy\");\n",
    "knn_f1 = np.load(\"../results/knn_f1.npy\");\n",
    "logreg_f1  = np.load(\"../results/logreg_f1.npy\");\n",
    "gb_f1  = np.load(\"../results/gb_f1.npy\");\n",
    "\n",
    "best_svm = joblib.load(\"../results/saved_models/svm_trained_model.joblib\");\n",
    "best_rf = joblib.load(\"../results/saved_models/rf_trained_model.joblib\");\n",
    "best_knn = joblib.load(\"../results/saved_models/knn_trained_model.joblib\");\n",
    "logreg = joblib.load(\"../results/saved_models/logreg_trained_model.joblib\");\n",
    "gb = joblib.load(\"../results/saved_models/gb_trained_model.joblib\");\n",
    "\n",
    "X_train = np.load(\"../results/saved_feature_matrices/X_train.npy\");\n",
    "X_val   = np.load(\"../results/saved_feature_matrices/X_val.npy\");\n",
    "X_test  = np.load(\"../results/saved_feature_matrices/X_test.npy\");\n",
    "\n",
    "y_train = np.load(\"../results/saved_feature_matrices/y_train.npy\");\n",
    "y_val   = np.load(\"../results/saved_feature_matrices/y_val.npy\");\n",
    "y_test  = np.load(\"../results/saved_feature_matrices/y_test.npy\");\n",
    "\n",
    "X_test_rf   = np.load(\"../results/X_test_rf.npy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893451d",
   "metadata": {},
   "source": [
    "### Classical models: Evaluation Metrices Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae2c6c",
   "metadata": {},
   "source": [
    "1. Classical models: Highlighting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "acc_list = [];\n",
    "prec_list = [];\n",
    "rec_list = [];\n",
    "f1_list = [];\n",
    "\n",
    "for p in preds:\n",
    "    acc_list.append(accuracy_score(y_test, p));\n",
    "    prec_list.append(precision_score(y_test, p, average=\"macro\"));\n",
    "    rec_list.append(recall_score(y_test, p, average=\"macro\"));\n",
    "    f1_list.append(f1_score(y_test, p, average=\"macro\"));\n",
    "\n",
    "# Create comparison dataframe\n",
    "perf_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Accuracy\": acc_list,\n",
    "    \"Precision\": prec_list,\n",
    "    \"Recall\": rec_list,\n",
    "    \"F1-score\": f1_list\n",
    "});\n",
    "\n",
    "\n",
    "perf_df\n",
    "\n",
    "# Printing the table and Highlighting the best model\n",
    "def highlight_best(s):\n",
    "    is_best = s == s.max();\n",
    "    return [\"background-color: red\" if v else \"\" for v in is_best];\n",
    "\n",
    "perf_df.style.apply(highlight_best, subset=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e404aa0",
   "metadata": {},
   "source": [
    "2. Classical models: Accuracy Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(perf_df[\"Model\"], perf_df[\"Accuracy\"]);\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Accuracy\");\n",
    "plt.title(\"Accuracy Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/accuracy_comparison.png\", dpi=300);\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c109aae",
   "metadata": {},
   "source": [
    "3. Classical models: F1-Score Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(perf_df[\"Model\"], perf_df[\"F1-score\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"F1-score\");\n",
    "plt.title(\"F1-score Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/f1_score_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad90aa1",
   "metadata": {},
   "source": [
    "4. Classical models: Precision & Recall grouped plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(perf_df));\n",
    "width = 0.35;\n",
    "\n",
    "plt.figure(figsize=(9,5));\n",
    "plt.bar(x - width/2, perf_df[\"Precision\"], width, label=\"Precision\");\n",
    "plt.bar(x + width/2, perf_df[\"Recall\"], width, label=\"Recall\");\n",
    "\n",
    "plt.xticks(x, perf_df[\"Model\"], rotation=30);\n",
    "plt.ylabel(\"Score\");\n",
    "plt.title(\"Precision and Recall Comparison\");\n",
    "plt.legend();\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/precision_recall_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378accb",
   "metadata": {},
   "source": [
    "5. Classical models: ROC multiclass comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Class labels (0,1,2)\n",
    "classes = np.unique(y_test);\n",
    "n_classes = len(classes);\n",
    "\n",
    "# Binarize true labels\n",
    "y_test_bin = label_binarize(y_test, classes=classes);\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "plt.figure(figsize=(9,7));\n",
    "\n",
    "for model_name, y_pred in zip(models, preds):\n",
    "    \n",
    "    # Binarize predictions\n",
    "    y_pred_bin = label_binarize(y_pred, classes=classes);\n",
    "    \n",
    "    fpr = dict();\n",
    "    tpr = dict();\n",
    "    roc_auc = dict();\n",
    "    \n",
    "    # ROC per class\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i]);\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i]);\n",
    "    \n",
    "    # Macro-average ROC\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]));\n",
    "    mean_tpr = np.zeros_like(all_fpr);\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i]);\n",
    "\n",
    "    mean_tpr /= n_classes;\n",
    "    macro_auc = auc(all_fpr, mean_tpr);\n",
    "\n",
    "    plt.plot(all_fpr, mean_tpr, lw=2,\n",
    "             label=f\"{model_name} (AUC = {macro_auc:.3f})\");\n",
    "\n",
    "# Random guess line\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=1);\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\");\n",
    "plt.ylabel(\"True Positive Rate\");\n",
    "plt.title(\"Multi-class ROC Curve Comparison (Macro-average)\");\n",
    "plt.legend(loc=\"lower right\");\n",
    "plt.grid(True);\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/roc_auc_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca8a2f",
   "metadata": {},
   "source": [
    "6. Classical models: Confusion matrix comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"];\n",
    "preds = [svm_test_pred, rf_test_pred, knn_test_pred, logreg_test_pred, gb_test_pred];\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9));\n",
    "axes = axes.ravel();\n",
    "\n",
    "for i, (name, y_pred) in enumerate(zip(models, preds)):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        ax=axes[i],\n",
    "        cmap=\"Blues\",\n",
    "        colorbar=False\n",
    "    );\n",
    "    axes[i].set_title(name);\n",
    "\n",
    "# remove empty subplot (6th one)\n",
    "axes[-1].axis(\"off\");\n",
    "\n",
    "fig.suptitle(\"Confusion Matrix Comparison – Classical Models\", fontsize=16);\n",
    "plt.tight_layout();\n",
    "plt.subplots_adjust(top=0.92);\n",
    "\n",
    "plt.savefig(\"../results/performance_plots/confusion_matrix_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37b04a",
   "metadata": {},
   "source": [
    "### Classical models: Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f20167",
   "metadata": {},
   "source": [
    "1. Classical models: Training time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Computational Efficiency: Training Time Comparison\n",
    "# ===================================================\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "train_times = [\n",
    "    svm_train_time, \n",
    "    rf_train_time, \n",
    "    knn_train_time, \n",
    "    logreg_train_time, \n",
    "    gb_train_time\n",
    "];\n",
    "\n",
    "# Create dataframe for display\n",
    "train_time_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Training Time (seconds)\": train_times\n",
    "});\n",
    "\n",
    "train_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439903ad",
   "metadata": {},
   "source": [
    "- Plot: Training time comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(models, train_times);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Training Time (seconds)\");\n",
    "plt.title(\"Training Time Comparison of Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/training_time_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7259810",
   "metadata": {},
   "source": [
    "2. Classical models: Inference time per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87caf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Inference Time per Video (seconds)\n",
    "# ============================================\n",
    "\n",
    "num_test_videos = len(y_test)\n",
    "\n",
    "inf_times = [\n",
    "    svm_test_time / num_test_videos,\n",
    "    rf_test_time / num_test_videos,\n",
    "    knn_test_time / num_test_videos,\n",
    "    logreg_test_time / num_test_videos,\n",
    "    gb_test_time / num_test_videos\n",
    "]\n",
    "\n",
    "models = [\"SVM\", \"Random Forest\", \"k-NN\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "\n",
    "inf_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Inference Time per Video (s)\": inf_times\n",
    "})\n",
    "\n",
    "inf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8eee2d",
   "metadata": {},
   "source": [
    "- Plot: Inference time per video (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Plot: Inference time per video\n",
    "# ============================================\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(inf_df[\"Model\"], inf_df[\"Inference Time per Video (s)\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Seconds per video\");\n",
    "plt.title(\"Inference Time per Video – Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/inference_time_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03a169",
   "metadata": {},
   "source": [
    "3. Classical models: Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Model Size (Disk footprint in MB)\n",
    "# ============================================\n",
    "\n",
    "model_files = {\n",
    "    \"SVM\": \"../results/saved_models/svm_trained_model.joblib\",\n",
    "    \"Random Forest\": \"../results/saved_models/rf_trained_model.joblib\",\n",
    "    \"k-NN\": \"../results/saved_models/knn_trained_model.joblib\",\n",
    "    \"Logistic Regression\": \"../results/saved_models/logreg_trained_model.joblib\",\n",
    "    \"Gradient Boosting\": \"../results/saved_models/gb_trained_model.joblib\"\n",
    "};\n",
    "\n",
    "sizes = [];\n",
    "\n",
    "for model, path in model_files.items():\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024);\n",
    "        sizes.append([model, size_mb]);\n",
    "    else:\n",
    "        sizes.append([model, np.nan]);\n",
    "\n",
    "size_df = pd.DataFrame(sizes, columns=[\"Model\", \"Model Size (MB)\"]);\n",
    "size_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd604c",
   "metadata": {},
   "source": [
    "- Plot: Model size comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Plot: Model size comparison\n",
    "# ============================================\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.bar(size_df[\"Model\"], size_df[\"Model Size (MB)\"]);\n",
    "plt.xticks(rotation=30);\n",
    "plt.ylabel(\"Model size (MB)\");\n",
    "plt.title(\"Model Size Comparison – Classical Models\");\n",
    "plt.tight_layout();\n",
    "plt.savefig(\"../results/performance_plots/model_size_comparison.png\", dpi=300);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db013820",
   "metadata": {},
   "source": [
    "4. Classical models: Data Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data splits\n",
    "\n",
    "#fractions = [0.1, 0.3, 0.5, 0.7, 1.0];\n",
    "fractions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "\n",
    "# Store original full training data\n",
    "\n",
    "X_full = np.vstack([X_train, X_val]);\n",
    "y_full = np.hstack([y_train, y_val]);\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVM\": best_svm,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"k-NN\": best_knn,\n",
    "    \"Logistic Regression\": logreg,\n",
    "    \"Gradient Boosting\": gb\n",
    "};\n",
    "\n",
    "# Computing learning curves:\n",
    "learning_results = {name: [] for name in models}\n",
    "\n",
    "for i, frac in enumerate(fractions):\n",
    "\n",
    "    print(f\"\\n========== Training with {int(frac*100)}% data ==========\")\n",
    "\n",
    "    X_sub, _, y_sub, _ = train_test_split(\n",
    "        X_full, y_full,\n",
    "        train_size=frac,\n",
    "        stratify=y_full,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for name, model in tqdm(models.items(),\n",
    "                             desc=f\"Models @ {int(frac*100)}%\",\n",
    "                             position=0,\n",
    "                             leave=True):\n",
    "\n",
    "        temp_model = clone(model)\n",
    "        temp_model.fit(X_sub, y_sub)\n",
    "\n",
    "        preds = temp_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "\n",
    "        learning_results[name].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efc652",
   "metadata": {},
   "source": [
    "- Plot: Learning curves comparison (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9627a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the learning curves\n",
    "\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for name, accs in learning_results.items():\n",
    "    plt.plot([int(f*100) for f in fractions], accs, marker=\"o\", label=name)\n",
    "\n",
    "plt.xlabel(\"Training data size (%)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Learning Curves – Data Efficiency Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/performance_plots/learning_curves.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9e39f",
   "metadata": {},
   "source": [
    "5. Classical models: Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff800452",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_results = []\n",
    "\n",
    "models = {\n",
    "    \"SVM\": best_svm,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"k-NN\": best_knn,\n",
    "    \"Logistic Regression\": logreg,\n",
    "    \"Gradient Boosting\": gb\n",
    "};\n",
    "\n",
    "for name, model in models.items():\n",
    "    tracemalloc.start()\n",
    "\n",
    "    if name == \"Random Forest\":\n",
    "        _ = model.predict(X_test_rf)\n",
    "    else:\n",
    "        _ = model.predict(X_test)\n",
    "\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    memory_results.append([name, peak/(1024*1024)]) # MB\n",
    "\n",
    "memory_df = pd.DataFrame(memory_results, columns=[\"Model\", \"Peak Memory Usage (MB)\"])\n",
    "memory_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ac05f",
   "metadata": {},
   "source": [
    "- Plot: Memory requirements (Classical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(memory_df[\"Model\"], memory_df[\"Peak Memory Usage (MB)\"])\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Peak RAM Usage (MB)\")\n",
    "plt.title(\"Memory Requirement Comparison (Inference)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/performance_plots/memory_usage_comparison.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353c5e0",
   "metadata": {},
   "source": [
    "6. Classical models: t-SNE Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22209a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- Normalize features (important for t-SNE) --------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# -------- Run t-SNE --------\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    learning_rate=200,\n",
    "    max_iter=1500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# -------- Plot --------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for label in np.unique(y_test):\n",
    "    idx = y_test == label\n",
    "    plt.scatter(X_tsne[idx,0], X_tsne[idx,1], s=30, label=f\"Class {label}\")\n",
    "\n",
    "plt.title(\"t-SNE visualization of handcrafted video features\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(\"../results/feature_visualizations/tsne_umap\", exist_ok=True)\n",
    "plt.savefig(\"../results/feature_visualizations/tsne_umap/tsne_classical.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f63b1f",
   "metadata": {},
   "source": [
    "7. Classical models: UMAP Visualization (Feature Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c879f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- Run UMAP --------\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_umap = umap_model.fit_transform(X_scaled)\n",
    "\n",
    "# -------- Plot --------\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for label in np.unique(y_test):\n",
    "    idx = y_test == label\n",
    "    plt.scatter(X_umap[idx,0], X_umap[idx,1], s=30, label=f\"Class {label}\")\n",
    "\n",
    "plt.title(\"UMAP visualization of handcrafted video features\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../results/feature_visualizations/tsne_umap/umap_classical.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
