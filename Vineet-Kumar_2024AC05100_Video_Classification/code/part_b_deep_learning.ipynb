{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ed35ee",
   "metadata": {},
   "source": [
    "Installing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg]);\n",
    "\n",
    "packages = [\"torch\", \"torchvision\"];\n",
    "\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split(\"-\")[0]);\n",
    "    except ImportError:\n",
    "        print(\"Installing package:\", p);\n",
    "        install(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160dd9d",
   "metadata": {},
   "source": [
    "importing modules and basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e45f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from data_loader import VideoDataset\n",
    "from models import ResNet18Temporal\n",
    "from utils import train_one_epoch, eval_one_epoch, EarlyStopping\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a35d5",
   "metadata": {},
   "source": [
    "Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a68fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb8d19",
   "metadata": {},
   "source": [
    "Dataset & loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35117296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "num_classes = len(class_map)\n",
    "\n",
    "dataset_root = \"../dataset_info/dataset\"\n",
    "\n",
    "train_ds = VideoDataset(\"../dataset_info/dataset/splits/train.csv\",\n",
    "                         dataset_root, class_map,\n",
    "                         num_frames=30, transform=train_tfms, train=True)\n",
    "\n",
    "val_ds = VideoDataset(\"../dataset_info/dataset/splits/val.csv\",\n",
    "                       dataset_root, class_map,\n",
    "                       num_frames=30, transform=val_tfms, train=False)\n",
    "\n",
    "test_ds = VideoDataset(\"../dataset_info/dataset/splits/test.csv\",\n",
    "                        dataset_root, class_map,\n",
    "                        num_frames=30, transform=val_tfms, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "val_loader   = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=4, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8829c",
   "metadata": {},
   "source": [
    "Model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af2964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ResNet18Temporal(num_classes=num_classes, pooling=\"avg\", dropout=0.5).to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "early_stop = EarlyStopping(patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440e3bb",
   "metadata": {},
   "source": [
    "Training loop (with early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b9035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   8%|▊         | 1/12 [00:57<10:34, 57.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/12] Train Loss: 1.2208 | Train Acc: 0.2915 || Val Loss: 1.1272 | Val Acc: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  17%|█▋        | 2/12 [01:55<09:38, 57.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/12] Train Loss: 1.2002 | Train Acc: 0.3727 || Val Loss: 1.0801 | Val Acc: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  25%|██▌       | 3/12 [02:53<08:40, 57.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/12] Train Loss: 1.1223 | Train Acc: 0.4096 || Val Loss: 1.0252 | Val Acc: 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 4/12 [03:51<07:43, 57.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/12] Train Loss: 1.1229 | Train Acc: 0.4059 || Val Loss: 0.9893 | Val Acc: 0.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  42%|████▏     | 5/12 [04:49<06:46, 58.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/12] Train Loss: 1.1007 | Train Acc: 0.4502 || Val Loss: 0.9714 | Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 6/12 [05:48<05:48, 58.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/12] Train Loss: 1.0545 | Train Acc: 0.4649 || Val Loss: 0.9374 | Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  58%|█████▊    | 7/12 [06:46<04:50, 58.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/12] Train Loss: 1.0878 | Train Acc: 0.4133 || Val Loss: 0.9172 | Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|██████▋   | 8/12 [07:44<03:53, 58.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/12] Train Loss: 1.0567 | Train Acc: 0.5240 || Val Loss: 0.9109 | Val Acc: 0.7111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  75%|███████▌  | 9/12 [08:43<02:55, 58.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/12] Train Loss: 1.0460 | Train Acc: 0.4945 || Val Loss: 0.8943 | Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  83%|████████▎ | 10/12 [09:41<01:56, 58.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/12] Train Loss: 1.0669 | Train Acc: 0.4576 || Val Loss: 0.8845 | Val Acc: 0.7111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  92%|█████████▏| 11/12 [10:40<00:58, 58.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/12] Train Loss: 1.0213 | Train Acc: 0.4945 || Val Loss: 0.8708 | Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 12/12 [11:38<00:00, 58.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [12/12] Train Loss: 0.9439 | Train Acc: 0.5609 || Val Loss: 0.8635 | Val Acc: 0.7333\n",
      "Training complete. Best Val Acc: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 12\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    val_loss, val_acc = eval_one_epoch(\n",
    "        model, val_loader, criterion, device)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_resnet18_temporal.pth\")\n",
    "\n",
    "    early_stop(val_loss)\n",
    "    if early_stop.stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete. Best Val Acc:\", best_val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527f589",
   "metadata": {},
   "source": [
    "Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e6d18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18Temporal(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best saved model\n",
    "model.load_state_dict(torch.load(\"best_resnet18_temporal.pth\", map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57976c1",
   "metadata": {},
   "source": [
    "Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e43245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f00cf3",
   "metadata": {},
   "source": [
    "Evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=list(class_map.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8309ad2",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=class_map.keys(),\n",
    "            yticklabels=class_map.keys(),\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – 2D CNN (ResNet-18)\")\n",
    "plt.show()\n",
    "plt.savefig(\"../results/confusion_matrices/2d_resnet18_confusion_matrix.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
