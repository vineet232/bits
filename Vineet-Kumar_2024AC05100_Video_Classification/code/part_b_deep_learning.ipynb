{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ed35ee",
   "metadata": {},
   "source": [
    "Installing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg]);\n",
    "\n",
    "packages = [\"torch\", \"torchvision\", \"seaborn\", \"psutil\"];\n",
    "\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split(\"-\")[0]);\n",
    "    except ImportError:\n",
    "        print(\"Installing package:\", p);\n",
    "        install(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160dd9d",
   "metadata": {},
   "source": [
    "importing modules and basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from data_loader import VideoDataset2D\n",
    "from models import ResNet18Temporal\n",
    "from utils import train_one_epoch, eval_one_epoch, EarlyStopping\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "import random\n",
    "import psutil\n",
    "from data_loader import VideoDataset3D\n",
    "from models import ResNet3D\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddd798",
   "metadata": {},
   "source": [
    "### Implementing 2D-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4d229",
   "metadata": {},
   "source": [
    "Reproducibility and Random Seed Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93221d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84738b9d",
   "metadata": {},
   "source": [
    "Creating required directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30610440",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"../dataset_info/sample_frames\", exist_ok=True);\n",
    "os.makedirs(\"../results\", exist_ok=True);\n",
    "os.makedirs(\"../results/confusion_matrices\", exist_ok=True);\n",
    "os.makedirs(\"../results/performance_plots\", exist_ok=True);\n",
    "os.makedirs(\"../results/feature_visualizations\", exist_ok=True);\n",
    "os.makedirs(\"../results/saved_models\", exist_ok=True);\n",
    "os.makedirs(\"../results/saved_feature_matrices\", exist_ok=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d34c5",
   "metadata": {},
   "source": [
    "Directory path for saving trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVE_DIR = \"../results/saved_models\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_2D_PATH = os.path.join(SAVE_DIR, \"best_resnet18_temporal.pth\")\n",
    "MODEL_3D_PATH = os.path.join(SAVE_DIR, \"best_resnet3d.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a35d5",
   "metadata": {},
   "source": [
    "Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb8d19",
   "metadata": {},
   "source": [
    "Dataset & loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35117296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "num_classes = len(class_map)\n",
    "\n",
    "dataset_root = \"../dataset_info/dataset\"\n",
    "\n",
    "train_ds_2d = VideoDataset2D(\"../dataset_info/dataset/splits/train.csv\",\n",
    "                         dataset_root, class_map,\n",
    "                         num_frames=20, transform=train_tfms, train=True)\n",
    "\n",
    "val_ds_2d = VideoDataset2D(\"../dataset_info/dataset/splits/val.csv\",\n",
    "                       dataset_root, class_map,\n",
    "                       num_frames=20, transform=val_tfms, train=False)\n",
    "\n",
    "test_ds_2d = VideoDataset2D(\"../dataset_info/dataset/splits/test.csv\",\n",
    "                        dataset_root, class_map,\n",
    "                        num_frames=20, transform=val_tfms, train=False)\n",
    "\n",
    "train_loader_2d = DataLoader(train_ds_2d, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader_2d   = DataLoader(val_ds_2d, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_loader_2d  = DataLoader(test_ds_2d, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8829c",
   "metadata": {},
   "source": [
    "Model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_2d = ResNet18Temporal(num_classes=num_classes, pooling=\"avg\", dropout=0.5).to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.9)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_2d.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "early_stop = EarlyStopping(patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440e3bb",
   "metadata": {},
   "source": [
    "Training loop (with early stopping) \n",
    "- This will take around 30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "best_val_acc = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "\n",
    "# ================= LOAD IF EXISTS =================\n",
    "if os.path.exists(MODEL_2D_PATH):\n",
    "\n",
    "    print(\"Found saved 2D model. Loading...\")\n",
    "\n",
    "    model_2d.load_state_dict(torch.load(MODEL_2D_PATH, map_location=device))\n",
    "    model_2d.to(device)\n",
    "    model_2d.eval()\n",
    "\n",
    "else:\n",
    "    print(\"No saved 2D model found. Starting training...\")\n",
    "\n",
    "\n",
    "    for epoch in trange(EPOCHS, desc=\"2D CNN Epochs\"):\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model_2d, train_loader_2d, optimizer, criterion, device)\n",
    "\n",
    "        val_loss, val_acc = eval_one_epoch(\n",
    "            model_2d, val_loader_2d, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model_2d.state_dict(), MODEL_2D_PATH)\n",
    "\n",
    "        early_stop(val_loss)\n",
    "        if early_stop.stop:\n",
    "            print(\"⏹ Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(\"2D CNN Training complete. Best Val Acc:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527f589",
   "metadata": {},
   "source": [
    "Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best saved model\n",
    "model_2d.load_state_dict(torch.load(MODEL_2D_PATH, map_location=device))\n",
    "model_2d.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")\n",
    "print(\"Backbone: ResNet-18 (ImageNet pretrained)\")\n",
    "print(\"Input: fixed-length RGB frame sequences (224x224)\")\n",
    "print(\"Temporal aggregation: Temporal pooling\")\n",
    "print(\"Classifier head: Dropout → Fully Connected (3 classes)\")\n",
    "\n",
    "print(\"Trainable parameters:\",\n",
    "      sum(p.numel() for p in model_2d.parameters() if p.requires_grad))\n",
    "\n",
    "print(\"Total parameters:\",\n",
    "      sum(p.numel() for p in model_2d.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57976c1",
   "metadata": {},
   "source": [
    "Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e43245",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_2d:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model_2d(x)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f00cf3",
   "metadata": {},
   "source": [
    "Evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=list(class_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8309ad2",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\",\n",
    "            xticklabels=class_map.keys(),\n",
    "            yticklabels=class_map.keys(),\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – 2D CNN (ResNet-18)\")\n",
    "plt.savefig(\"../results/confusion_matrices/2d_resnet18_confusion_matrix.png\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a6f57",
   "metadata": {},
   "source": [
    "Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve – 2D CNN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../results/performance_plots/2dcnn_loss_curve.png\", dpi=300, bbox_inches=\"tight\");\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accs, label=\"Train Accuracy\")\n",
    "plt.plot(val_accs, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve – 2D CNN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../results/performance_plots/2dcnn_accuracy_curve.png\", dpi=300, bbox_inches=\"tight\");\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85435e",
   "metadata": {},
   "source": [
    "Inference time (computational analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader_2d))\n",
    "x = x.to(device)\n",
    "\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    _ = model_2d(x)\n",
    "end = time.time()\n",
    "\n",
    "inf_time_2d = (end - start) / x.size(0)  \n",
    "\n",
    "print(\"Inference time per batch (seconds):\", end-start)\n",
    "print(\"Approx inference time per video (seconds)):\", inf_time_2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613172e3",
   "metadata": {},
   "source": [
    "Model size (parameter count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params_2d = sum(p.numel() for p in model_2d.parameters())\n",
    "trainable_params_2d = sum(p.numel() for p in model_2d.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Total parameters:\", total_params_2d)\n",
    "print(\"Trainable parameters:\", trainable_params_2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e96057",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = np.where(all_preds != all_labels)[0]\n",
    "print(\"Wrong predictions:\", len(wrong_idx))\n",
    "\n",
    "if len(wrong_idx) > 0:\n",
    "    for i in wrong_idx[:5]:\n",
    "\n",
    "        row = test_ds_2d.data.iloc[i]   # CSV row\n",
    "        video_path = row[\"clip_path\"]\n",
    "\n",
    "        true_label = list(class_map.keys())[all_labels[i]]\n",
    "        pred_label = list(class_map.keys())[all_preds[i]]\n",
    "\n",
    "        print(\"Video:\", video_path)\n",
    "        print(\"True:\", true_label, \"| Pred:\", pred_label)\n",
    "        print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d2833",
   "metadata": {},
   "source": [
    "File size on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODEL_2D_PATH\n",
    "file_size_mb_2d = os.path.getsize(model_path) / (1024 * 1024)\n",
    "\n",
    "print(\"Saved model file size: {:.2f} MB\".format(file_size_mb_2d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0f0c6",
   "metadata": {},
   "source": [
    "Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2331b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU memory allocated:\",\n",
    "          torch.cuda.memory_allocated() / (1024**2), \"MB\")\n",
    "    print(\"GPU memory reserved:\",\n",
    "          torch.cuda.memory_reserved() / (1024**2), \"MB\")\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "ram_mb = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "print(\"Current RAM usage:\", ram_mb, \"MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38208fcc",
   "metadata": {},
   "source": [
    "Saving the results for comparitive analyisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f160c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2d = accuracy_score(all_labels, all_preds)\n",
    "p2d, r2d, f12d, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "stats_2d = {\n",
    "    \"accuracy\": acc2d,\n",
    "    \"precision\": p2d,\n",
    "    \"recall\": r2d,\n",
    "    \"f1\": f12d,\n",
    "    \"inference_time\": inf_time_2d,\n",
    "    \"params\": total_params_2d,\n",
    "    \"model_size_mb\": file_size_mb_2d\n",
    "}\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "with open(\"../results/stats_2d.json\", \"w\") as f:\n",
    "    json.dump(stats_2d, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142c7b6",
   "metadata": {},
   "source": [
    "### Implementing 3D CNN - I3D (Resnet 3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8f547",
   "metadata": {},
   "source": [
    "3D Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc04593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_3d = VideoDataset3D(\"../dataset_info/dataset/splits/train.csv\", dataset_root, class_map,\n",
    "                             num_frames=16, transform=train_tfms, train=True)\n",
    "\n",
    "val_ds_3d   = VideoDataset3D(\"../dataset_info/dataset/splits/val.csv\", dataset_root, class_map,\n",
    "                             num_frames=16, transform=val_tfms, train=False)\n",
    "\n",
    "test_ds_3d  = VideoDataset3D(\"../dataset_info/dataset/splits/test.csv\", dataset_root, class_map,\n",
    "                             num_frames=16, transform=val_tfms, train=False)\n",
    "\n",
    "train_loader_3d = DataLoader(train_ds_3d, batch_size=2, shuffle=True, num_workers=4)\n",
    "val_loader_3d   = DataLoader(val_ds_3d, batch_size=2, shuffle=False, num_workers=4)\n",
    "test_loader_3d  = DataLoader(test_ds_3d, batch_size=2, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "x3d, _ = next(iter(test_loader_3d))\n",
    "print(x3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ee5de",
   "metadata": {},
   "source": [
    "Model, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c88a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"PullUps\": 0, \"Punch\": 1, \"PushUps\": 2}\n",
    "num_classes = len(class_map)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_3d = ResNet3D(num_classes=num_classes, dropout=0.5, freeze_backbone=True).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.9)\n",
    "optimizer = torch.optim.Adam(model_3d.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "early_stop = EarlyStopping(patience=4)\n",
    "\n",
    "out = model_3d(x3d.to(device))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9e34e",
   "metadata": {},
   "source": [
    "Training loop\n",
    "- This will take around 30 minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "best_val_acc = 0\n",
    "\n",
    "train_losses_3d, val_losses_3d = [], []\n",
    "train_accs_3d, val_accs_3d = [], []\n",
    "\n",
    "\n",
    "# ================= LOAD IF EXISTS =================\n",
    "if os.path.exists(MODEL_3D_PATH):\n",
    "\n",
    "    print(\"Found saved 3D model. Loading...\")\n",
    "\n",
    "    model_3d.load_state_dict(torch.load(MODEL_3D_PATH, map_location=device))\n",
    "    model_3d.to(device)\n",
    "    model_3d.eval()\n",
    "\n",
    "else:\n",
    "    print(\"No saved model found. Starting training...\")\n",
    "\n",
    "\n",
    "    for epoch in trange(EPOCHS, desc=\"3D CNN Epochs\"):\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model_3d, train_loader_3d, optimizer, criterion, device)\n",
    "\n",
    "        val_loss, val_acc = eval_one_epoch(\n",
    "            model_3d, val_loader_3d, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        train_losses_3d.append(train_loss)\n",
    "        val_losses_3d.append(val_loss)\n",
    "        train_accs_3d.append(train_acc)\n",
    "        val_accs_3d.append(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model_3d.state_dict(), MODEL_3D_PATH)\n",
    "\n",
    "        early_stop(val_loss)\n",
    "        if early_stop.stop:\n",
    "            print(\"⏹ Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(\"3D CNN Training complete. Best Val Acc:\", best_val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc36773",
   "metadata": {},
   "source": [
    "Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0126b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.load_state_dict(torch.load(MODEL_3D_PATH, map_location=device))\n",
    "model_3d.eval()\n",
    "\n",
    "all_preds_3d, all_labels_3d = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_3d:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model_3d(x)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "\n",
    "        all_preds_3d.extend(preds.cpu().numpy())\n",
    "        all_labels_3d.extend(y.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17feed2f",
   "metadata": {},
   "source": [
    "Metrics + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"3D CNN Test Accuracy:\", accuracy_score(all_labels_3d, all_preds_3d))\n",
    "print(classification_report(all_labels_3d, all_preds_3d, target_names=class_map.keys()))\n",
    "\n",
    "cm3d = confusion_matrix(all_labels_3d, all_preds_3d)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm3d, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_map.keys(),\n",
    "            yticklabels=class_map.keys())\n",
    "plt.title(\"Confusion Matrix – 3D CNN\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6d014",
   "metadata": {},
   "source": [
    "Learning curves (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa43c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses_3d, label=\"Train Loss\")\n",
    "plt.plot(val_losses_3d, label=\"Val Loss\")\n",
    "plt.title(\"3D CNN Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accs_3d, label=\"Train Acc\")\n",
    "plt.plot(val_accs_3d, label=\"Val Acc\")\n",
    "plt.title(\"3D CNN Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f6610",
   "metadata": {},
   "source": [
    "Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23150187",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader_3d))\n",
    "x = x.to(device)\n",
    "\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    _ = model_3d(x)\n",
    "end = time.time()\n",
    "\n",
    "inf_time_3d = (end - start) / x.size(0)  \n",
    "\n",
    "print(\"Inference time per batch:\", end-start)\n",
    "print(\"Approx inference time per video:\", inf_time_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bca80",
   "metadata": {},
   "source": [
    "Model size (parameter count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a565a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params_3d = sum(p.numel() for p in model_3d.parameters())\n",
    "trainable_params_3d = sum(p.numel() for p in model_3d.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"3D CNN Total parameters:\", total_params_3d)\n",
    "print(\"3D CNN Trainable parameters:\", trainable_params_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000eca5",
   "metadata": {},
   "source": [
    "Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220211f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = np.where(np.array(all_preds_3d) != np.array(all_labels_3d))[0]\n",
    "print(\"Total wrong predictions (3D CNN):\", len(wrong_idx))\n",
    "\n",
    "if len(wrong_idx) > 0:\n",
    "    #for i in wrong_idx[:5]:\n",
    "    for i in wrong_idx:    \n",
    "        row = test_ds_3d.data.iloc[i]\n",
    "        video_path = row[\"clip_path\"]\n",
    "\n",
    "        true_label = list(class_map.keys())[all_labels_3d[i]]\n",
    "        pred_label = list(class_map.keys())[all_preds_3d[i]]\n",
    "\n",
    "        print(\"Video:\", video_path)\n",
    "        print(\"True:\", true_label, \"| Pred:\", pred_label)\n",
    "        print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0625b",
   "metadata": {},
   "source": [
    "Saved model file size (disk storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9480376",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODEL_3D_PATH\n",
    "file_size_mb_3d = os.path.getsize(model_path) / (1024 * 1024)\n",
    "\n",
    "print(\"3D CNN Saved model size: {:.2f} MB\".format(file_size_mb_3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd562d4",
   "metadata": {},
   "source": [
    "Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU memory allocated:\",\n",
    "          torch.cuda.memory_allocated() / (1024**2), \"MB\")\n",
    "    print(\"GPU memory reserved:\",\n",
    "          torch.cuda.memory_reserved() / (1024**2), \"MB\")\n",
    "else:\n",
    "    print(\"GPU not available. Running on CPU.\")\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "ram_mb = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "print(\"Current CPU RAM usage: {:.2f} MB\".format(ram_mb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c060e",
   "metadata": {},
   "source": [
    "Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3d = accuracy_score(all_labels_3d, all_preds_3d)\n",
    "p3d, r3d, f13d, _ = precision_recall_fscore_support(all_labels_3d, all_preds_3d, average=\"macro\")\n",
    "\n",
    "stats_3d = {\n",
    "    \"accuracy\": acc3d,\n",
    "    \"precision\": p3d,\n",
    "    \"recall\": r3d,\n",
    "    \"f1\": f13d,\n",
    "    \"inference_time\": inf_time_3d,\n",
    "    \"params\": total_params_3d,\n",
    "    \"model_size_mb\": file_size_mb_3d\n",
    "}\n",
    "\n",
    "with open(\"../results/stats_3d.json\", \"w\") as f:\n",
    "    json.dump(stats_3d, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
