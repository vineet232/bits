{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fbac01",
   "metadata": {},
   "source": [
    "# Lab 3A: Low-Level Feature Extraction\n",
    "**Course:** AIML ZG531 - Video Analysis  \n",
    "**Module:** 3 - Feature Extraction  \n",
    "**Topic:** Edge, Corner, Texture, and Color Features from Video  \n",
    "**Author:** Seetha Parameswaran\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Extract and visualize low-level spatial features from video frames\n",
    "- Compare edge detection methods (Canny vs. Sobel)\n",
    "- Apply corner detection algorithms (Harris vs. Shi-Tomasi)\n",
    "- Compute texture descriptors using Local Binary Patterns\n",
    "- Analyze color distributions through histogram features\n",
    "- Understand the role of hand-crafted features in video analysis\n",
    "\n",
    "\n",
    "This script extracts low-level spatial features from video frames:\n",
    "1. Edge Detection (Canny, Sobel)\n",
    "2. Corner Detection (Harris, Shi-Tomasi)\n",
    "3. Texture Features (Local Binary Patterns)\n",
    "4. Color Histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "class LowLevelFeatureExtractor:\n",
    "    \"\"\"Extract low-level features from video frames\"\"\"\n",
    "    \n",
    "    def __init__(self, video_path):\n",
    "        \"\"\"\n",
    "        Initialize feature extractor\n",
    "        \n",
    "        Args:\n",
    "            video_path: Path to input video file\n",
    "        \"\"\"\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video file: {video_path}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        print(f\"Video Properties:\")\n",
    "        print(f\"  Resolution: {self.width}x{self.height}\")\n",
    "        print(f\"  FPS: {self.fps}\")\n",
    "        print(f\"  Total Frames: {self.total_frames}\")\n",
    "    \n",
    "    def extract_edges_canny(self, frame, low_threshold=50, high_threshold=150):\n",
    "        \"\"\"\n",
    "        Extract edges using Canny edge detector\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            low_threshold: Lower threshold for hysteresis\n",
    "            high_threshold: Upper threshold for hysteresis\n",
    "            \n",
    "        Returns:\n",
    "            Edge map\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "        return edges\n",
    "    \n",
    "    def extract_edges_sobel(self, frame):\n",
    "        \"\"\"\n",
    "        Extract edges using Sobel operator\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            \n",
    "        Returns:\n",
    "            Edge magnitude map\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Compute gradients in x and y directions\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "        # Compute gradient magnitude\n",
    "        magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        magnitude = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "        \n",
    "        return magnitude\n",
    "    \n",
    "    def extract_corners_harris(self, frame, block_size=2, ksize=3, k=0.04, threshold=0.01):\n",
    "        \"\"\"\n",
    "        Detect corners using Harris corner detector\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            block_size: Size of neighborhood for corner detection\n",
    "            ksize: Aperture parameter for Sobel operator\n",
    "            k: Harris detector free parameter\n",
    "            threshold: Threshold for corner response (relative to max)\n",
    "            \n",
    "        Returns:\n",
    "            Corner map, corner coordinates\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.float32(gray)\n",
    "        \n",
    "        # Detect corners\n",
    "        dst = cv2.cornerHarris(gray, block_size, ksize, k)\n",
    "        \n",
    "        # Threshold for corner detection\n",
    "        corner_map = dst > threshold * dst.max()\n",
    "        \n",
    "        # Get corner coordinates\n",
    "        corners = np.argwhere(corner_map)\n",
    "        \n",
    "        return corner_map.astype(np.uint8) * 255, corners\n",
    "    \n",
    "    def extract_corners_shi_tomasi(self, frame, max_corners=100, quality_level=0.01, min_distance=10):\n",
    "        \"\"\"\n",
    "        Detect corners using Shi-Tomasi (Good Features to Track)\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            max_corners: Maximum number of corners to detect\n",
    "            quality_level: Quality threshold (0-1)\n",
    "            min_distance: Minimum distance between corners\n",
    "            \n",
    "        Returns:\n",
    "            Corner coordinates\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect corners\n",
    "        corners = cv2.goodFeaturesToTrack(\n",
    "            gray,\n",
    "            maxCorners=max_corners,\n",
    "            qualityLevel=quality_level,\n",
    "            minDistance=min_distance\n",
    "        )\n",
    "        \n",
    "        return corners\n",
    "    \n",
    "    def extract_texture_lbp(self, frame, num_points=8, radius=1):\n",
    "        \"\"\"\n",
    "        Extract texture features using Local Binary Patterns\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            num_points: Number of circularly symmetric neighbor points\n",
    "            radius: Radius of circle\n",
    "            \n",
    "        Returns:\n",
    "            LBP feature map, LBP histogram\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Compute LBP\n",
    "        lbp = local_binary_pattern(gray, num_points, radius, method='uniform')\n",
    "        \n",
    "        # Compute LBP histogram\n",
    "        n_bins = num_points + 2  # uniform patterns + non-uniform\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        \n",
    "        # Normalize histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        \n",
    "        return lbp.astype(np.uint8), hist\n",
    "    \n",
    "    def extract_color_histogram(self, frame, bins=32):\n",
    "        \"\"\"\n",
    "        Extract color histogram features\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame (BGR)\n",
    "            bins: Number of bins per channel\n",
    "            \n",
    "        Returns:\n",
    "            Histograms for each channel (B, G, R)\n",
    "        \"\"\"\n",
    "        histograms = []\n",
    "        colors = ('b', 'g', 'r')\n",
    "        \n",
    "        for i, color in enumerate(colors):\n",
    "            hist = cv2.calcHist([frame], [i], None, [bins], [0, 256])\n",
    "            hist = hist.flatten()\n",
    "            hist = hist / (hist.sum() + 1e-7)  # Normalize\n",
    "            histograms.append(hist)\n",
    "        \n",
    "        return histograms\n",
    "    \n",
    "    def process_frame(self, frame_idx):\n",
    "        \"\"\"\n",
    "        Extract all low-level features from a single frame\n",
    "        \n",
    "        Args:\n",
    "            frame_idx: Frame index to process\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all extracted features\n",
    "        \"\"\"\n",
    "        # Set frame position\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = self.cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            raise ValueError(f\"Cannot read frame {frame_idx}\")\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Edge features\n",
    "        features['edges_canny'] = self.extract_edges_canny(frame)\n",
    "        features['edges_sobel'] = self.extract_edges_sobel(frame)\n",
    "        \n",
    "        # Corner features\n",
    "        harris_map, harris_coords = self.extract_corners_harris(frame)\n",
    "        features['corners_harris_map'] = harris_map\n",
    "        features['corners_harris_coords'] = harris_coords\n",
    "        \n",
    "        shi_tomasi_corners = self.extract_corners_shi_tomasi(frame)\n",
    "        features['corners_shi_tomasi'] = shi_tomasi_corners\n",
    "        \n",
    "        # Texture features\n",
    "        lbp_map, lbp_hist = self.extract_texture_lbp(frame)\n",
    "        features['texture_lbp_map'] = lbp_map\n",
    "        features['texture_lbp_hist'] = lbp_hist\n",
    "        \n",
    "        # Color features\n",
    "        color_hists = self.extract_color_histogram(frame)\n",
    "        features['color_hist_b'] = color_hists[0]\n",
    "        features['color_hist_g'] = color_hists[1]\n",
    "        features['color_hist_r'] = color_hists[2]\n",
    "        \n",
    "        # Store original frame\n",
    "        features['original_frame'] = frame\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def visualize_features(self, features, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize extracted features\n",
    "        \n",
    "        Args:\n",
    "            features: Dictionary of extracted features\n",
    "            save_path: Path to save visualization (optional)\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # Original frame\n",
    "        ax1 = plt.subplot(3, 4, 1)\n",
    "        frame_rgb = cv2.cvtColor(features['original_frame'], cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(frame_rgb)\n",
    "        ax1.set_title('Original Frame')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Canny edges\n",
    "        ax2 = plt.subplot(3, 4, 2)\n",
    "        ax2.imshow(features['edges_canny'], cmap='gray')\n",
    "        ax2.set_title('Canny Edges')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Sobel edges\n",
    "        ax3 = plt.subplot(3, 4, 3)\n",
    "        ax3.imshow(features['edges_sobel'], cmap='gray')\n",
    "        ax3.set_title('Sobel Edges')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Harris corners\n",
    "        ax4 = plt.subplot(3, 4, 4)\n",
    "        frame_with_harris = frame_rgb.copy()\n",
    "        if len(features['corners_harris_coords']) > 0:\n",
    "            for y, x in features['corners_harris_coords'][:100]:  # Limit for visualization\n",
    "                cv2.circle(frame_with_harris, (x, y), 3, (255, 0, 0), -1)\n",
    "        ax4.imshow(frame_with_harris)\n",
    "        ax4.set_title(f'Harris Corners ({len(features[\"corners_harris_coords\"])})')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # Shi-Tomasi corners\n",
    "        ax5 = plt.subplot(3, 4, 5)\n",
    "        frame_with_shi_tomasi = frame_rgb.copy()\n",
    "        if features['corners_shi_tomasi'] is not None:\n",
    "            for corner in features['corners_shi_tomasi']:\n",
    "                x, y = corner.ravel()\n",
    "                cv2.circle(frame_with_shi_tomasi, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "        ax5.imshow(frame_with_shi_tomasi)\n",
    "        ax5.set_title(f'Shi-Tomasi Corners ({len(features[\"corners_shi_tomasi\"]) if features[\"corners_shi_tomasi\"] is not None else 0})')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # LBP texture\n",
    "        ax6 = plt.subplot(3, 4, 6)\n",
    "        ax6.imshow(features['texture_lbp_map'], cmap='gray')\n",
    "        ax6.set_title('LBP Texture Map')\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # LBP histogram\n",
    "        ax7 = plt.subplot(3, 4, 7)\n",
    "        ax7.bar(range(len(features['texture_lbp_hist'])), features['texture_lbp_hist'])\n",
    "        ax7.set_title('LBP Histogram')\n",
    "        ax7.set_xlabel('LBP Pattern')\n",
    "        ax7.set_ylabel('Frequency')\n",
    "        \n",
    "        # Color histograms\n",
    "        ax8 = plt.subplot(3, 4, 8)\n",
    "        colors = ['blue', 'green', 'red']\n",
    "        for i, (hist, color) in enumerate(zip(\n",
    "            [features['color_hist_b'], features['color_hist_g'], features['color_hist_r']],\n",
    "            colors\n",
    "        )):\n",
    "            ax8.plot(hist, color=color, alpha=0.7, label=color.upper())\n",
    "        ax8.set_title('Color Histograms')\n",
    "        ax8.set_xlabel('Bin')\n",
    "        ax8.set_ylabel('Frequency')\n",
    "        ax8.legend()\n",
    "        \n",
    "        # Edge statistics\n",
    "        ax9 = plt.subplot(3, 4, 9)\n",
    "        edge_stats = {\n",
    "            'Canny': np.sum(features['edges_canny'] > 0),\n",
    "            'Sobel': np.sum(features['edges_sobel'] > 128)\n",
    "        }\n",
    "        ax9.bar(edge_stats.keys(), edge_stats.values())\n",
    "        ax9.set_title('Edge Pixel Count')\n",
    "        ax9.set_ylabel('Count')\n",
    "        \n",
    "        # Corner statistics\n",
    "        ax10 = plt.subplot(3, 4, 10)\n",
    "        corner_stats = {\n",
    "            'Harris': len(features['corners_harris_coords']),\n",
    "            'Shi-Tomasi': len(features['corners_shi_tomasi']) if features['corners_shi_tomasi'] is not None else 0\n",
    "        }\n",
    "        ax10.bar(corner_stats.keys(), corner_stats.values())\n",
    "        ax10.set_title('Corner Count')\n",
    "        ax10.set_ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Visualization saved to: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def process_video_sample(self, sample_frames=5, output_dir='features_output'):\n",
    "        \"\"\"\n",
    "        Process sample frames from the video\n",
    "        \n",
    "        Args:\n",
    "            sample_frames: Number of frames to sample\n",
    "            output_dir: Directory to save outputs\n",
    "        \"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Sample frame indices uniformly\n",
    "        frame_indices = np.linspace(0, self.total_frames - 1, sample_frames, dtype=int)\n",
    "        \n",
    "        print(f\"\\nProcessing {sample_frames} sample frames...\")\n",
    "        \n",
    "        for i, frame_idx in enumerate(frame_indices):\n",
    "            print(f\"\\nProcessing frame {frame_idx}/{self.total_frames} ({i+1}/{sample_frames})...\")\n",
    "            \n",
    "            # Extract features\n",
    "            features = self.process_frame(frame_idx)\n",
    "            \n",
    "            # Visualize and save\n",
    "            save_path = os.path.join(output_dir, f'features_frame_{frame_idx:06d}.png')\n",
    "            self.visualize_features(features, save_path=save_path)\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"  Harris corners: {len(features['corners_harris_coords'])}\")\n",
    "            print(f\"  Shi-Tomasi corners: {len(features['corners_shi_tomasi']) if features['corners_shi_tomasi'] is not None else 0}\")\n",
    "            print(f\"  Canny edge pixels: {np.sum(features['edges_canny'] > 0)}\")\n",
    "            print(f\"  LBP histogram entropy: {-np.sum(features['texture_lbp_hist'] * np.log(features['texture_lbp_hist'] + 1e-7)):.3f}\")\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Release video capture\"\"\"\n",
    "        if hasattr(self, 'cap'):\n",
    "            self.cap.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to demonstrate feature extraction\"\"\"\n",
    "    \n",
    "    # Example usage\n",
    "    video_path = \"vid.avi\"  # Replace with your video path\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Low-Level Feature Extraction from Video\")\n",
    "    print(\"Module 3: Video Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize extractor\n",
    "        extractor = LowLevelFeatureExtractor(video_path)\n",
    "        \n",
    "        # Process sample frames\n",
    "        extractor.process_video_sample(sample_frames=5, output_dir='low_level_features')\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Feature extraction completed successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. Video file exists at the specified path\")\n",
    "        print(\"2. Required libraries are installed: opencv-python, scikit-image, matplotlib\")\n",
    "        print(\"\\nInstall with: pip install opencv-python scikit-image matplotlib numpy\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7b234",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Feature Categories\n",
    "\n",
    "1. **Edge Features**\n",
    "   - Canny: Multi-stage, hysteresis thresholding, optimal edge detection\n",
    "   - Sobel: Gradient-based, simple, fast computation\n",
    "   - Use case: Object boundaries, motion boundaries\n",
    "\n",
    "2. **Corner Features**\n",
    "   - Harris: Classic, rotation-invariant, good for tracking\n",
    "   - Shi-Tomasi: Improved quality measure, better feature distribution\n",
    "   - Use case: Feature tracking, structure from motion\n",
    "\n",
    "3. **Texture Features**\n",
    "   - LBP: Rotation-invariant, efficient, local patterns\n",
    "   - Histogram: Statistical texture characterization\n",
    "   - Use case: Material classification, face recognition\n",
    "\n",
    "4. **Color Features**\n",
    "   - Channel histograms: Distribution-based representation\n",
    "   - Normalized: Scale-invariant, illumination robust\n",
    "   - Use case: Object recognition, scene understanding\n",
    "\n",
    "### Practical Insights\n",
    "- **Complementary Nature:** Different features capture different aspects\n",
    "- **Computational Cost:** Hand-crafted features are fast but limited\n",
    "- **Robustness:** Corner features more stable across frames than edges\n",
    "- **Dimensionality:** Color/texture features are compact representations\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise Questions\n",
    "\n",
    "1. **Conceptual**: Why do corner features remain more stable across frames compared to edge features in video sequences?\n",
    "\n",
    "2. **Analysis**: Compare Harris and Shi-Tomasi corner counts. Which method provides better spatial distribution? Why might this matter for tracking?\n",
    "\n",
    "3. **Application**: For a gait analysis system (medical case study), which low-level features would be most useful for detecting key body points? Justify your choice.\n",
    "\n",
    "4. **Implementation**: Modify the code to extract features at multiple scales. How does scale affect edge and corner detection?\n",
    "\n",
    "5. **Critical Thinking**: LBP histograms lose spatial information. Propose a method to retain spatial structure while using LBP features.\n",
    "\n",
    "6. **Comparison**: Calculate the correlation between LBP histogram entropy and edge pixel count across frames. What does this relationship indicate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
