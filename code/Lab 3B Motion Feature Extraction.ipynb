{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c4ee5d",
   "metadata": {},
   "source": [
    "# Lab 3B: Motion Feature Extraction\n",
    "**Course:** AIML ZG531 - Video Analysis  \n",
    "**Module:** 3 - Feature Extraction  \n",
    "**Topic:** Temporal Motion Features Using Frame Differencing, Background Subtraction, and Optical Flow  \n",
    "**Author:** Seetha Parameswaran\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Extract motion information using frame differencing techniques\n",
    "- Implement background subtraction for foreground detection\n",
    "- Compute sparse optical flow using Lucas-Kanade method\n",
    "- Calculate dense optical flow using Farneback algorithm\n",
    "- Visualize and interpret motion patterns in videos\n",
    "- Understand the brightness constancy assumption and aperture problem\n",
    "\n",
    "This script extracts motion features:\n",
    "1. Frame Differencing\n",
    "2. Background Subtraction (GMM)\n",
    "3. Optical Flow (Lucas-Kanade, Farneback) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "class MotionFeatureExtractor:\n",
    "    \"\"\"Extract motion features from video\"\"\"\n",
    "    \n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "        \n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        print(f\"Video: {self.width}x{self.height}, {self.fps} fps, {self.total_frames} frames\")\n",
    "    \n",
    "    def frame_differencing(self, frame1, frame2, threshold=30):\n",
    "        \"\"\"\n",
    "        Compute frame difference\n",
    "        \n",
    "        Args:\n",
    "            frame1, frame2: Consecutive frames\n",
    "            threshold: Difference threshold\n",
    "        Returns:\n",
    "            Binary difference mask\n",
    "        \"\"\"\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        diff = cv2.absdiff(gray1, gray2)\n",
    "        _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        return diff, thresh\n",
    "    \n",
    "    def background_subtraction(self, frames, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Background subtraction using MOG2\n",
    "        \n",
    "        Args:\n",
    "            frames: List of frames\n",
    "            learning_rate: Learning rate for background model\n",
    "        Returns:\n",
    "            Foreground masks\n",
    "        \"\"\"\n",
    "        bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=500, varThreshold=16, detectShadows=True\n",
    "        )\n",
    "        \n",
    "        masks = []\n",
    "        for frame in frames:\n",
    "            mask = bg_subtractor.apply(frame, learningRate=learning_rate)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        return masks\n",
    "    \n",
    "    def optical_flow_lucas_kanade(self, frame1, frame2, max_corners=100):\n",
    "        \"\"\"\n",
    "        Sparse optical flow using Lucas-Kanade\n",
    "        \n",
    "        Args:\n",
    "            frame1, frame2: Consecutive frames\n",
    "            max_corners: Max feature points\n",
    "        Returns:\n",
    "            Feature points and flow vectors\n",
    "        \"\"\"\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect corners in first frame\n",
    "        p0 = cv2.goodFeaturesToTrack(\n",
    "            gray1, maxCorners=max_corners, \n",
    "            qualityLevel=0.01, minDistance=10\n",
    "        )\n",
    "        \n",
    "        if p0 is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Calculate optical flow\n",
    "        p1, status, _ = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None)\n",
    "        \n",
    "        # Select good points\n",
    "        good_old = p0[status == 1]\n",
    "        good_new = p1[status == 1]\n",
    "        \n",
    "        return good_old, good_new\n",
    "    \n",
    "    def optical_flow_farneback(self, frame1, frame2):\n",
    "        \"\"\"\n",
    "        Dense optical flow using Farneback method\n",
    "        \n",
    "        Args:\n",
    "            frame1, frame2: Consecutive frames\n",
    "        Returns:\n",
    "            Flow field (u, v components)\n",
    "        \"\"\"\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            gray1, gray2, None,\n",
    "            pyr_scale=0.5, levels=3, winsize=15,\n",
    "            iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "        )\n",
    "        \n",
    "        return flow\n",
    "    \n",
    "    def visualize_motion_features(self, frame1, frame2, save_path=None):\n",
    "        \"\"\"Visualize all motion features\"\"\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        \n",
    "        # Original frames\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        ax1.imshow(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Frame t')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        ax2.imshow(cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Frame t+1')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Frame differencing\n",
    "        diff, thresh = self.frame_differencing(frame1, frame2)\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        ax3.imshow(diff, cmap='hot')\n",
    "        ax3.set_title('Frame Difference')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        ax4.imshow(thresh, cmap='gray')\n",
    "        ax4.set_title('Thresholded Difference')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # Background subtraction\n",
    "        masks = self.background_subtraction([frame1, frame2])\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        ax5.imshow(masks[1], cmap='gray')\n",
    "        ax5.set_title('Background Subtraction')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Lucas-Kanade optical flow\n",
    "        p0, p1 = self.optical_flow_lucas_kanade(frame1, frame2)\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        frame_lk = cv2.cvtColor(frame2.copy(), cv2.COLOR_BGR2RGB)\n",
    "        if p0 is not None and p1 is not None:\n",
    "            for (x0, y0), (x1, y1) in zip(p0, p1):\n",
    "                cv2.arrowedLine(frame_lk, (int(x0), int(y0)), \n",
    "                              (int(x1), int(y1)), (0, 255, 0), 2, tipLength=0.3)\n",
    "        ax6.imshow(frame_lk)\n",
    "        ax6.set_title(f'Lucas-Kanade Flow ({len(p0) if p0 is not None else 0} points)')\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # Farneback dense optical flow\n",
    "        flow = self.optical_flow_farneback(frame1, frame2)\n",
    "        \n",
    "        # Flow magnitude\n",
    "        magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        ax7.imshow(magnitude, cmap='jet')\n",
    "        ax7.set_title('Flow Magnitude')\n",
    "        ax7.axis('off')\n",
    "        \n",
    "        # Flow direction (HSV visualization)\n",
    "        hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "        hsv[..., 1] = 255\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        ax8.imshow(rgb)\n",
    "        ax8.set_title('Flow Direction (HSV)')\n",
    "        ax8.axis('off')\n",
    "        \n",
    "        # Flow statistics\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        stats_text = f\"Flow Statistics:\\n\"\n",
    "        stats_text += f\"Mean magnitude: {np.mean(magnitude):.2f}\\n\"\n",
    "        stats_text += f\"Max magnitude: {np.max(magnitude):.2f}\\n\"\n",
    "        stats_text += f\"Motion pixels (>1): {np.sum(magnitude > 1)}\\n\"\n",
    "        ax9.text(0.1, 0.5, stats_text, fontsize=10, verticalalignment='center')\n",
    "        ax9.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Saved: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def process_video_sample(self, sample_pairs=5, output_dir='motion_features'):\n",
    "        \"\"\"Process sample frame pairs\"\"\"\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Sample frame pairs\n",
    "        frame_indices = np.linspace(0, self.total_frames - 10, sample_pairs, dtype=int)\n",
    "        \n",
    "        print(f\"\\nProcessing {sample_pairs} frame pairs...\")\n",
    "        \n",
    "        for i, frame_idx in enumerate(frame_indices):\n",
    "            print(f\"\\nPair {i+1}/{sample_pairs}: frames {frame_idx} and {frame_idx+1}\")\n",
    "            \n",
    "            # Read consecutive frames\n",
    "            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret1, frame1 = self.cap.read()\n",
    "            ret2, frame2 = self.cap.read()\n",
    "            \n",
    "            if not (ret1 and ret2):\n",
    "                print(f\"Cannot read frames {frame_idx}\")\n",
    "                continue\n",
    "            \n",
    "            # Visualize\n",
    "            save_path = os.path.join(output_dir, f'motion_frame_{frame_idx:06d}.png')\n",
    "            self.visualize_motion_features(frame1, frame2, save_path)\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'cap'):\n",
    "            self.cap.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Motion Feature Extraction\n",
      "Module 3: Video Analysis\n",
      "============================================================\n",
      "\n",
      "Error: Cannot open video: /home/seetha/PythonScriptsCourses/PythonScriptsCourses/Video Analytics/data/Life by the river_1080p.mp4\n",
      "\n",
      "Install: pip install opencv-python matplotlib numpy\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    video_path = \"vid.avi\"  # Replace with your video\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Motion Feature Extraction\")\n",
    "    print(\"Module 3: Video Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        extractor = MotionFeatureExtractor(video_path)\n",
    "        extractor.process_video_sample(sample_pairs=5)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Completed!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"\\nInstall: pip install opencv-python matplotlib numpy\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d80f5",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Motion Extraction Methods\n",
    "\n",
    "1. **Frame Differencing**\n",
    "   - Simplest motion detection: |I(t) - I(t-1)|\n",
    "   - Fast, low computational cost\n",
    "   - Limitations: Sensitive to noise, no velocity information\n",
    "   - Use case: Basic motion detection, trigger systems\n",
    "\n",
    "2. **Background Subtraction (MOG2)**\n",
    "   - Gaussian Mixture Model for background modeling\n",
    "   - Adapts to gradual changes (lighting, weather)\n",
    "   - Handles shadows (detectShadows parameter)\n",
    "   - Use case: Surveillance, people counting, abandoned object detection\n",
    "\n",
    "3. **Lucas-Kanade (Sparse Flow)**\n",
    "   - Tracks specific feature points\n",
    "   - Assumes brightness constancy and small motion\n",
    "   - Computationally efficient\n",
    "   - Use case: Object tracking, structure from motion\n",
    "\n",
    "4. **Farneback (Dense Flow)**\n",
    "   - Computes flow for every pixel\n",
    "   - Polynomial expansion approach\n",
    "   - More computationally intensive\n",
    "   - Use case: Video stabilization, motion segmentation, action recognition\n",
    "\n",
    "### Motion Representation\n",
    "- **Magnitude:** Speed of motion\n",
    "- **Direction:** Angle of motion (HSV visualization)\n",
    "- **Flow Vectors:** Complete motion field description\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise Questions\n",
    "\n",
    "1. **Conceptual**: Explain why the brightness constancy assumption fails in real-world scenarios. Give three specific examples from different application domains.\n",
    "\n",
    "2. **Analysis**: Compare the number of motion pixels detected by frame differencing vs. background subtraction. Which method has fewer false positives? Why?\n",
    "\n",
    "3. **Application**: For autonomous vehicle pedestrian detection, would you use sparse or dense optical flow? Consider real-time constraints and safety requirements.\n",
    "\n",
    "4. **Implementation**: Modify the optical flow code to detect only large motions (magnitude > threshold). How does this affect the detection of different types of activities?\n",
    "\n",
    "5. **Critical Thinking**: The aperture problem causes ambiguity in optical flow. Design a strategy to detect and handle regions affected by this problem.\n",
    "\n",
    "6. **Algorithmic**: Background subtraction adapts with a learning rate. Experiment with different learning rates (0.0001, 0.01, 0.1). How does this affect detection of stationary vs. moving objects?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
